{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming 4B using Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paraemter values for the 1D keyboad are stored in global variables; you can change them\n",
    "pr_hit = 0.6\n",
    "pr_miss = 0.4\n",
    "deg_kb = 2\n",
    "\n",
    "pr_repeat = 0.2\n",
    "pr_moveOn = 0.8\n",
    "deg_sp = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Key functions implemented so far"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## getPrTableForPossibleInitialStates(lengthOfWord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5714285714285714, 0.2857142857142857, 0.14285714285714285]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# C++: void getPrTableForPossibleInitialStates(lengthOfWord):\n",
    "# ==> \n",
    "# Python: getPrTableForPossibleInitialStates(prTable, lengthOfWord):\n",
    "#           return the information in the prTable directly\n",
    "def getPrTableForPossibleInitialStates(lengthOfWord):\n",
    "    missDistance = range( 1, lengthOfWord+1 )\n",
    "    exponentialDegrade = [ (1/deg_sp)**i    for i in missDistance]\n",
    "    scalingConstant = 1 / sum(exponentialDegrade)\n",
    "    return [scalingConstant*degrade for degrade in exponentialDegrade]\n",
    "    \n",
    "\n",
    "# Test the function to get the probabilities of the possible first states\n",
    "#      for a word of 3 characters (such as \"his\" in our handout)\n",
    "pr_repeat = 0.2\n",
    "pr_moveOn = 0.8\n",
    "deg_sp = 2\n",
    "getPrTableForPossibleInitialStates(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## getPrTableForPossibleInitialStatesGivenTheWord(Word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5714285714285714, 0.2857142857142857, 0.14285714285714285]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A variant that accomplishes the same thing given a word (as a string)\n",
    "def getPrTableForPossibleInitialStatesGivenTheWord(Word):\n",
    "    missDistance = range( 1, len(Word)+1 )\n",
    "    exponentialDegrade = [ (1/deg_sp)**i    for i in missDistance]\n",
    "    scalingConstant = 1 / sum(exponentialDegrade)\n",
    "    return [scalingConstant*degrade for degrade in exponentialDegrade]\n",
    "    \n",
    "    \n",
    "# Test the function to get the probabilities of the possible first states\n",
    "#      for the word \"his\" \n",
    "pr_repeat = 0.2\n",
    "pr_moveOn = 0.8\n",
    "deg_sp = 2\n",
    "getPrTableForPossibleInitialStatesGivenTheWord(\"his\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## getPrTableForPossibleNextStates(lengthOfWord_Plus1, currentState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2, 0.4571428571428572, 0.2285714285714286, 0.1142857142857143]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# C++ \n",
    "# void getPrTableForPossibleNextStates(double transitionPrTable[], \n",
    "#                                      int sizeOfTable, int currentState)\n",
    "# ==>\n",
    "# Python \n",
    "# getPrTableForPossibleNextStates(lengthOfWord_Plus1, currentState)\n",
    "# return the transitionPrTable\n",
    "\n",
    "def getPrTableForPossibleNextStates(lengthOfWord_Plus1, currentState):\n",
    "    statesAsIndices = range( lengthOfWord_Plus1 )\n",
    "    distances = [state - currentState for state in statesAsIndices ]\n",
    "    exponentialDegrade = [ (1/deg_sp)**i if i>0 else 0 for i in distances]\n",
    "    scalingConstant = pr_moveOn/sum(exponentialDegrade)\n",
    "    probabilitiesOfPossibleFirstStates = (\n",
    "        [ scalingConstant*degrade for degrade in exponentialDegrade] )\n",
    "    probabilitiesOfPossibleFirstStates[currentState] = pr_repeat\n",
    "    return probabilitiesOfPossibleFirstStates\n",
    "\n",
    "\n",
    "#Test the implementation\n",
    "getPrTableForPossibleNextStates(len(\"his\")+1, 0) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## getPrTableForPossibleNextStatesGivenWord(word, currentState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2, 0.4571428571428572, 0.2285714285714286, 0.1142857142857143]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A convenient variant\n",
    "# Python \n",
    "# getPrTableForPossibleNextStates(word, int currentState)\n",
    "# return the transitionPrTable\n",
    "\n",
    "def getPrTableForPossibleNextStatesGivenWord(word, currentState):\n",
    "    lengthOfWord_Plus1 =  len(word) +1\n",
    "    statesAsIndices = range( lengthOfWord_Plus1 )\n",
    "    distances = [state - currentState for state in statesAsIndices ]\n",
    "    exponentialDegrade = [ (1/deg_sp)**i if i>0 else 0 for i in distances]\n",
    "    scalingConstant = pr_moveOn/sum(exponentialDegrade)\n",
    "    probabilitiesOfPossibleFirstStates = (\n",
    "        [ scalingConstant*degrade for degrade in exponentialDegrade] )\n",
    "    probabilitiesOfPossibleFirstStates[currentState] = pr_repeat\n",
    "    return probabilitiesOfPossibleFirstStates\n",
    "\n",
    "#Test the implementation\n",
    "currentState = 0\n",
    "getPrTableForPossibleNextStatesGivenWord(\"his\", currentState)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prCharGiveCharState(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Probability of touching x when trying to type y\n",
    "def prCharGiveCharState(x, y):\n",
    "    if x==y:\n",
    "        return pr_hit\n",
    "    \n",
    "    diffASCII = range(1,26)\n",
    "    missdist = [min(n, 26-n) for n in diffASCII ]\n",
    "    exponentialDegrade = [(1/deg_kb)**i for i in missdist]\n",
    "    constant_x= pr_miss/sum(exponentialDegrade)\n",
    "    \n",
    "    distASCII_x_y = abs( ord(x) - ord(y) ) \n",
    "    distKB_x_y = min(distASCII_x_y, 26-distASCII_x_y )\n",
    "    return constant_x* (1/deg_kb)** distKB_x_y "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## take1SampleFrom1PrSpace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 0, 0, 0, 0, 2, 2, 1, 0]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# C++: int take1SampleFrom1PrSpace(double prTable[], int sizeOfTable)\n",
    "# ==>\n",
    "# Python: take1SampleFrom1PrSpace(prTable)\n",
    "#  the size of the table can be implicitly determined \n",
    "def take1SampleFrom1PrSpace(prTable):\n",
    "    probabilityThresholds = np.add.accumulate(prTable)\n",
    "    sample = np.random.random()\n",
    "    choice = (sample > probabilityThresholds).sum()\n",
    "    # print(\"Sample=\", sample, \",\\t choice=\", choice)\n",
    "    return choice\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "prTable = np.array([0.25, 0.5, 0.25])\n",
    "[take1SampleFrom1PrSpace(prTable) for i in range(20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.249836, 0.499929, 0.250235])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use bin count to check empirical frequencies observed\n",
    "np.bincount( [take1SampleFrom1PrSpace(prTable) for i in range(1000000)] )/1000000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## getKeyboardProbabilityTable\n",
    "### note: this is a simple variant of prCharGiveCharState(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.00000000e-01, 1.33333501e-01, 4.44445002e-02, 1.48148334e-02,\n",
       "       4.93827780e-03, 1.64609260e-03, 5.48697533e-04, 1.82899178e-04,\n",
       "       6.09663926e-05, 2.03221309e-05, 6.77404362e-06, 2.25801454e-06,\n",
       "       7.52671513e-07, 2.50890504e-07, 7.52671513e-07, 2.25801454e-06,\n",
       "       6.77404362e-06, 2.03221309e-05, 6.09663926e-05, 1.82899178e-04,\n",
       "       5.48697533e-04, 1.64609260e-03, 4.93827780e-03, 1.48148334e-02,\n",
       "       4.44445002e-02, 1.33333501e-01])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#C++: void getKeyboardProbabilityTable(char charToType, double prTable[])\n",
    "#==>\n",
    "#Python: getKeyboardProbabilityTable(charToType) \n",
    "#        to return the probabilities of getting a, b, ..., y, z\n",
    "#        as a numpy array\n",
    "#Note: This is simply a simple variant of prCharGiveCharState(x, y):\n",
    "\n",
    "def getKeyboardProbabilityTable(charToType):\n",
    "    #First determine the scaling constant for the exponential degrading\n",
    "    diffASCII = range(1,26)\n",
    "    missdist = [min(n, 26-n) for n in diffASCII ]\n",
    "    exponentialDegrade = [(1/deg_kb)**i for i in missdist]\n",
    "    scalingConstant = pr_miss/sum(exponentialDegrade)    \n",
    "    \n",
    "    #Set up an empty probability table \n",
    "    prTable = np.empty(26)\n",
    "    y = charToType\n",
    "    \n",
    "    # for each x in a to z,\n",
    "    # set up a loop to determine the probability of touching x \n",
    "    #     when trying to type y (i.e.charToType)\n",
    "    # store the results in the probability table accordingly\n",
    "    for i, x in enumerate(\"abcdefghijklmnopqrstuvwxyz\"):\n",
    "        if x==y:\n",
    "            prTable[i] = pr_hit\n",
    "        else:\n",
    "            distASCII_x_y = abs( ord(x) - ord(y) ) \n",
    "            distKB_x_y = min(distASCII_x_y, 26-distASCII_x_y )\n",
    "            prTable[i] = scalingConstant * (1/deg_kb)** distKB_x_y \n",
    "    \n",
    "    return prTable\n",
    "\n",
    "\n",
    "#Test the implementation\n",
    "pr_hit = 0.6\n",
    "pr_miss = 0.4\n",
    "deg_kb = 3\n",
    "\n",
    "getKeyboardProbabilityTable('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.33333501e-01, 6.00000000e-01, 1.33333501e-01, 4.44445002e-02,\n",
       "       1.48148334e-02, 4.93827780e-03, 1.64609260e-03, 5.48697533e-04,\n",
       "       1.82899178e-04, 6.09663926e-05, 2.03221309e-05, 6.77404362e-06,\n",
       "       2.25801454e-06, 7.52671513e-07, 2.50890504e-07, 7.52671513e-07,\n",
       "       2.25801454e-06, 6.77404362e-06, 2.03221309e-05, 6.09663926e-05,\n",
       "       1.82899178e-04, 5.48697533e-04, 1.64609260e-03, 4.93827780e-03,\n",
       "       1.48148334e-02, 4.44445002e-02])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#More test on the implementation\n",
    "getKeyboardProbabilityTable('b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999999"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#More test on the implementation\n",
    "getKeyboardProbabilityTable('b').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## typeOneChar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'y', 'e', 't', 'p', 'i', 'r', 'l', 'h', 'y']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# C++: char typeOneChar(char charToType)\n",
    "# Python: typeOneChar(charToType) \n",
    "#   use  take1SampleFrom1PrSpace and\n",
    "#        getKeyboardProbabilityTable to\n",
    "#   simulate typing charToType and return the resulting character pressed \n",
    "\n",
    "def typeOneChar(charToType):\n",
    "    keys = \"abcdefghijklmnopqrstuvwxyz\" \n",
    "    prTable = getKeyboardProbabilityTable(charToType)\n",
    "    indexOfKeyPressed = take1SampleFrom1PrSpace( prTable )\n",
    "    return keys[ indexOfKeyPressed ]\n",
    "\n",
    "#Test the implementatiton\n",
    "pr_hit = 0.2\n",
    "pr_miss = 0.8\n",
    "deg_kb = 1.2\n",
    "\n",
    "#Type 'a' for 10 times and see the results\n",
    "[typeOneChar('a') for i in range(10) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'y', 'd', 'c', 'b', 'c', 'y', 'z', 'd', 'y']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#More test the implementatiton\n",
    "pr_hit = 0.2\n",
    "pr_miss = 0.8\n",
    "deg_kb = 2\n",
    "\n",
    "#Type 'a' for 10 times under a different setting and see the results\n",
    "[typeOneChar('a') for i in range(10) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  typeOneWord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C++: void typeOneWord( char word[], char output[], \n",
    "#                        bool traceON = false, int maxOutput=100)\n",
    "# Python: typeOneWord( word, trace=False )\n",
    "#      simulate the typing of the given word (a string) and\n",
    "#      return the resulted string\n",
    "\n",
    "def typeOneWord(word, trace=False):\n",
    "    #Special States\n",
    "    I_stateIndex = -1 \n",
    "    F_stateIndex = len(word)\n",
    "    \n",
    "    # Step 0: Simulation of leaving the starting state I to enter some (first) state \n",
    "    #        to enter a regular state as the current state: throw a dice\n",
    "    charOutputsObservedSofar = \"_\"\n",
    "    stateTrajectorySofar = \"I\"\n",
    "    prTable = getPrTableForPossibleInitialStatesGivenTheWord(word)\n",
    "\n",
    "    currentState_index = take1SampleFrom1PrSpace(prTable)\n",
    "    currentState_char = word[ currentState_index  ]\n",
    "\n",
    "    if trace:\n",
    "        print( \"First state reached after leaving I: (index, char)=\", \n",
    "               (currentState_index, currentState_char) \n",
    "             )\n",
    "    \n",
    "    while( currentState_index != F_stateIndex): # not the Final state F yet.\n",
    "        # Step 1: Simulation of typing a character given the current state: throw a dice\n",
    "        charTyped = typeOneChar(currentState_char)\n",
    "        charOutputsObservedSofar += charTyped\n",
    "        stateTrajectorySofar += currentState_char\n",
    "\n",
    "        if trace:\n",
    "            print( \"Current state: (index, char)=\", (currentState_index, currentState_char) )\n",
    "            print( charTyped, \" is pressed when trying to type \", currentState_char)\n",
    "            print( \"char outputs so far:\\t\", charOutputsObservedSofar )\n",
    "            print( \"state trajectory so far:\", stateTrajectorySofar )\n",
    "            print()\n",
    "\n",
    "        # Step 2: Simulation of leaving the current state to enter one of the possble next states\n",
    "        #       : throw a dice\n",
    "        prTable = getPrTableForPossibleNextStatesGivenWord(word, currentState_index)\n",
    "        nextState_index = take1SampleFrom1PrSpace(prTable)\n",
    "        nextState_char = word[ nextState_index  ] if (nextState_index<F_stateIndex) else \"F\"\n",
    "        if trace:\n",
    "            print( \"next state to enter: \", (nextState_index, \n",
    "                                             nextState_char) )\n",
    "\n",
    "        currentState_index = nextState_index\n",
    "        currentState_char = nextState_char \n",
    "\n",
    "    if trace:\n",
    "        print(\"Finish typing the word \", word)\n",
    "        print( \"char outputs:\\t\\t\", charOutputsObservedSofar+\"_\" )\n",
    "        print( \"state trajectory:\\t\", stateTrajectorySofar+\"F\" )\n",
    "        \n",
    "    return charOutputsObservedSofar[1:]\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First state reached after leaving I: (index, char)= (0, 'h')\n",
      "Current state: (index, char)= (0, 'h')\n",
      "h  is pressed when trying to type  h\n",
      "char outputs so far:\t _h\n",
      "state trajectory so far: Ih\n",
      "\n",
      "next state to enter:  (1, 'i')\n",
      "Current state: (index, char)= (1, 'i')\n",
      "i  is pressed when trying to type  i\n",
      "char outputs so far:\t _hi\n",
      "state trajectory so far: Ihi\n",
      "\n",
      "next state to enter:  (2, 's')\n",
      "Current state: (index, char)= (2, 's')\n",
      "s  is pressed when trying to type  s\n",
      "char outputs so far:\t _his\n",
      "state trajectory so far: Ihis\n",
      "\n",
      "next state to enter:  (3, 'F')\n",
      "Finish typing the word  his\n",
      "char outputs:\t\t _his_\n",
      "state trajectory:\t IhisF\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'his'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_hit = 0.9\n",
    "pr_miss = 0.1\n",
    "deg_kb = 4\n",
    "\n",
    "pr_repeat = 0.1\n",
    "pr_moveOn = 0.9\n",
    "deg_sp = 4\n",
    "\n",
    "word = \"his\"\n",
    "\n",
    "#See the trace of the simulation of typing one word\n",
    "typeOneWord( word, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s',\n",
       " 'his',\n",
       " 'hiss',\n",
       " 'his',\n",
       " 'is',\n",
       " 'his',\n",
       " 'his',\n",
       " 'his',\n",
       " 'hi',\n",
       " 'h',\n",
       " 'hi',\n",
       " 'iss',\n",
       " 's',\n",
       " 'hi',\n",
       " 'hiu',\n",
       " 'his',\n",
       " 'his',\n",
       " 'iis',\n",
       " 'hs',\n",
       " 'fs',\n",
       " 'hit',\n",
       " 'his',\n",
       " 'his',\n",
       " 'iis',\n",
       " 'hu',\n",
       " 'h',\n",
       " 'i',\n",
       " 'hs',\n",
       " 'hhhs',\n",
       " 'his',\n",
       " 'hsq',\n",
       " 'hit',\n",
       " 'hs',\n",
       " 'hi',\n",
       " 'his',\n",
       " 'hs',\n",
       " 'his',\n",
       " 'i',\n",
       " 'hks',\n",
       " 'hs',\n",
       " 'hi',\n",
       " 'his',\n",
       " 'his',\n",
       " 'hs',\n",
       " 'gs',\n",
       " 'is',\n",
       " 'iisr',\n",
       " 'hi',\n",
       " 'hs',\n",
       " 'hkr',\n",
       " 'hhiss',\n",
       " 'hi',\n",
       " 'is',\n",
       " 'hs',\n",
       " 'hhiss',\n",
       " 'ht',\n",
       " 'his',\n",
       " 'hhis',\n",
       " 'his',\n",
       " 'hs',\n",
       " 'hiu',\n",
       " 'hs',\n",
       " 'hhis',\n",
       " 'hi',\n",
       " 'is',\n",
       " 'hhis',\n",
       " 'hit',\n",
       " 'his',\n",
       " 'is',\n",
       " 'hs',\n",
       " 'hs',\n",
       " 'is',\n",
       " 'is',\n",
       " 'hhis',\n",
       " 'his',\n",
       " 'hlis',\n",
       " 'hi',\n",
       " 'hss',\n",
       " 'his',\n",
       " 'is',\n",
       " 'hiis',\n",
       " 'hhis',\n",
       " 'hs',\n",
       " 'hi',\n",
       " 'hhis',\n",
       " 'hs',\n",
       " 'hs',\n",
       " 'hiss',\n",
       " 'hs',\n",
       " 'hs',\n",
       " 'hjs',\n",
       " 'his',\n",
       " 'hjs',\n",
       " 'hs',\n",
       " 'hhss',\n",
       " 'hiis',\n",
       " 'hhiis',\n",
       " 'hs',\n",
       " 'his',\n",
       " 'hjs',\n",
       " 'his',\n",
       " 'iis',\n",
       " 'hi',\n",
       " 'his',\n",
       " 'ghhs',\n",
       " 'ius',\n",
       " 'hi',\n",
       " 'hs',\n",
       " 'iis',\n",
       " 'is',\n",
       " 'hs',\n",
       " 'hhs',\n",
       " 'g',\n",
       " 'his',\n",
       " 'his',\n",
       " 'h',\n",
       " 'hi',\n",
       " 'his',\n",
       " 'is',\n",
       " 'his',\n",
       " 'hi',\n",
       " 'his',\n",
       " 's',\n",
       " 'hiss',\n",
       " 'h',\n",
       " 'hii',\n",
       " 'his',\n",
       " 'hi',\n",
       " 'hi',\n",
       " 'hi',\n",
       " 'hi',\n",
       " 'hit',\n",
       " 'gisss',\n",
       " 's',\n",
       " 'is',\n",
       " 'iiss',\n",
       " 'is',\n",
       " 'jr',\n",
       " 'h',\n",
       " 'his',\n",
       " 'hiss',\n",
       " 'his',\n",
       " 'iis',\n",
       " 'is',\n",
       " 'hi',\n",
       " 'his',\n",
       " 'hht',\n",
       " 'his',\n",
       " 's',\n",
       " 'his',\n",
       " 'hi',\n",
       " 'ihs',\n",
       " 'hs',\n",
       " 'h',\n",
       " 'his',\n",
       " 'his',\n",
       " 'hs',\n",
       " 'hs',\n",
       " 'hs',\n",
       " 'hhs',\n",
       " 's',\n",
       " 'his',\n",
       " 'his',\n",
       " 'hi',\n",
       " 'his',\n",
       " 'his',\n",
       " 'his',\n",
       " 'is',\n",
       " 'hi',\n",
       " 'hs',\n",
       " 'hss',\n",
       " 'hi',\n",
       " 'hiss',\n",
       " 'his',\n",
       " 's',\n",
       " 'hh',\n",
       " 'hisss',\n",
       " 'hi',\n",
       " 'his',\n",
       " 'his',\n",
       " 'iiss',\n",
       " 'hs',\n",
       " 'hs',\n",
       " 'hs',\n",
       " 'i',\n",
       " 'hi',\n",
       " 'his',\n",
       " 'hiis',\n",
       " 'hhis',\n",
       " 'his',\n",
       " 'gss',\n",
       " 'is',\n",
       " 'his',\n",
       " 'hiss',\n",
       " 'h',\n",
       " 'hs',\n",
       " 'hr',\n",
       " 'hiis',\n",
       " 'hiiis',\n",
       " 'his',\n",
       " 'i',\n",
       " 'gis',\n",
       " 'his',\n",
       " 'hi',\n",
       " 'his',\n",
       " 'hs',\n",
       " 'hi',\n",
       " 'is',\n",
       " 'hjs',\n",
       " 'his',\n",
       " 'is',\n",
       " 'hhis',\n",
       " 'hiit',\n",
       " 'hs',\n",
       " 'his',\n",
       " 'is',\n",
       " 'hisss',\n",
       " 'hs',\n",
       " 'i',\n",
       " 'hiss',\n",
       " 'his',\n",
       " 'is',\n",
       " 'his',\n",
       " 'hi',\n",
       " 'his',\n",
       " 'jis',\n",
       " 'hi',\n",
       " 'hii',\n",
       " 'h',\n",
       " 'is',\n",
       " 'is',\n",
       " 'his',\n",
       " 'is',\n",
       " 'his',\n",
       " 'js',\n",
       " 'hih',\n",
       " 'hhss',\n",
       " 's',\n",
       " 'hhis',\n",
       " 'hs',\n",
       " 'i',\n",
       " 'lss',\n",
       " 'iis',\n",
       " 's',\n",
       " 'his',\n",
       " 'is',\n",
       " 'iss',\n",
       " 'fhis',\n",
       " 'his',\n",
       " 'iis',\n",
       " 'is',\n",
       " 'hi',\n",
       " 'jisr',\n",
       " 'hhis',\n",
       " 'hhis',\n",
       " 'his',\n",
       " 'hs',\n",
       " 'his',\n",
       " 'hiis',\n",
       " 'his',\n",
       " 'hhis',\n",
       " 'hhi',\n",
       " 'hit',\n",
       " 'his',\n",
       " 'hi',\n",
       " 'his',\n",
       " 's',\n",
       " 'hiis',\n",
       " 'iiis',\n",
       " 'hi',\n",
       " 's',\n",
       " 'is',\n",
       " 'his',\n",
       " 'hir',\n",
       " 'hiq',\n",
       " 'his',\n",
       " 'js',\n",
       " 'his',\n",
       " 'hj',\n",
       " 'h',\n",
       " 'his',\n",
       " 'hir',\n",
       " 'hss',\n",
       " 'i',\n",
       " 's',\n",
       " 's',\n",
       " 'is',\n",
       " 'hs',\n",
       " 'ir',\n",
       " 'hiss',\n",
       " 'is',\n",
       " 'sss',\n",
       " 's',\n",
       " 'hss',\n",
       " 'h',\n",
       " 'hiis',\n",
       " 'iis',\n",
       " 'hi',\n",
       " 'iis',\n",
       " 'his',\n",
       " 'ffs',\n",
       " 'hs',\n",
       " 'hi',\n",
       " 'hi',\n",
       " 'hiss',\n",
       " 'hir',\n",
       " 'his',\n",
       " 'gis',\n",
       " 'hs',\n",
       " 'ir',\n",
       " 'hiss',\n",
       " 'hi',\n",
       " 'hjs',\n",
       " 'gir',\n",
       " 'en',\n",
       " 'hjis',\n",
       " 'hr',\n",
       " 'iii',\n",
       " 'hiss',\n",
       " 'hs',\n",
       " 'hjs',\n",
       " 'his',\n",
       " 'hs',\n",
       " 'hgs',\n",
       " 'hs',\n",
       " 'hiss',\n",
       " 'hisss',\n",
       " 'hi',\n",
       " 'hii',\n",
       " 'hhis',\n",
       " 'i',\n",
       " 'his',\n",
       " 'is',\n",
       " 'hs',\n",
       " 'hhis',\n",
       " 'hjs',\n",
       " 'gi',\n",
       " 'his',\n",
       " 'his',\n",
       " 'his',\n",
       " 'iis',\n",
       " 'is',\n",
       " 'hs',\n",
       " 'his',\n",
       " 'i',\n",
       " 'it',\n",
       " 'hs',\n",
       " 'hhhi',\n",
       " 'hiis',\n",
       " 'hs',\n",
       " 'is',\n",
       " 'hss',\n",
       " 'his',\n",
       " 'hi',\n",
       " 'hi',\n",
       " 'hs',\n",
       " 'is',\n",
       " 'is',\n",
       " 'his',\n",
       " 'his',\n",
       " 'hi',\n",
       " 'hiis',\n",
       " 'hiss',\n",
       " 'hs',\n",
       " 'hi',\n",
       " 'i',\n",
       " 'is',\n",
       " 'hr',\n",
       " 'hs',\n",
       " 'his',\n",
       " 'i',\n",
       " 'his',\n",
       " 'iis',\n",
       " 'is',\n",
       " 'hius',\n",
       " 'his',\n",
       " 'hi',\n",
       " 'is',\n",
       " 'hi',\n",
       " 'hijr',\n",
       " 'ii',\n",
       " 'is',\n",
       " 'hiiu',\n",
       " 'ss',\n",
       " 'hiss',\n",
       " 'hhs',\n",
       " 'his',\n",
       " 's',\n",
       " 'ir',\n",
       " 'his',\n",
       " 'hg',\n",
       " 'is',\n",
       " 'his',\n",
       " 'hhs',\n",
       " 'i',\n",
       " 'iss',\n",
       " 'is',\n",
       " 'fhs',\n",
       " 'he',\n",
       " 'his',\n",
       " 'is',\n",
       " 'his',\n",
       " 'his',\n",
       " 'hiis',\n",
       " 'hh',\n",
       " 'hs',\n",
       " 'h',\n",
       " 's',\n",
       " 'i',\n",
       " 'is',\n",
       " 'hs',\n",
       " 'his',\n",
       " 'it',\n",
       " 'iss',\n",
       " 'his',\n",
       " 'his',\n",
       " 'gi',\n",
       " 'hjs',\n",
       " 'hiss',\n",
       " 'hi',\n",
       " 'his',\n",
       " 'hiss',\n",
       " 'i',\n",
       " 'hi',\n",
       " 'ht',\n",
       " 'hs',\n",
       " 'hi',\n",
       " 'his',\n",
       " 'his',\n",
       " 'g',\n",
       " 'hi',\n",
       " 'ghs',\n",
       " 'hhj',\n",
       " 'ht',\n",
       " 'is',\n",
       " 'hs',\n",
       " 'hiss',\n",
       " 'hhi',\n",
       " 'gs',\n",
       " 'hiii',\n",
       " 'hi',\n",
       " 'hhi',\n",
       " 'hii',\n",
       " 'hi',\n",
       " 'hss',\n",
       " 'ii',\n",
       " 'hhis',\n",
       " 'his',\n",
       " 'hs',\n",
       " 'gs',\n",
       " 'hss',\n",
       " 'hs',\n",
       " 'iis',\n",
       " 'his',\n",
       " 'is',\n",
       " 'issss',\n",
       " 'ii',\n",
       " 'is',\n",
       " 'hhi',\n",
       " 'hss',\n",
       " 'hjr',\n",
       " 'fis',\n",
       " 'hs',\n",
       " 'hs',\n",
       " 'jis',\n",
       " 'i',\n",
       " 's',\n",
       " 's',\n",
       " 'hiss',\n",
       " 'hi',\n",
       " 'i',\n",
       " 'hi',\n",
       " 'hi',\n",
       " 'his',\n",
       " 'his',\n",
       " 'his',\n",
       " 'hms',\n",
       " 'hs',\n",
       " 'hiis',\n",
       " 'his',\n",
       " 'his',\n",
       " 'his',\n",
       " 'hhss',\n",
       " 'hks',\n",
       " 'h',\n",
       " 'his',\n",
       " 'hijs',\n",
       " 'hi',\n",
       " 'h',\n",
       " 'hi',\n",
       " 's',\n",
       " 's',\n",
       " 'is',\n",
       " 'hss',\n",
       " 'his',\n",
       " 'is',\n",
       " 'is',\n",
       " 'is',\n",
       " 'is',\n",
       " 'his',\n",
       " 'his',\n",
       " 'h',\n",
       " 'is',\n",
       " 's',\n",
       " 'hi',\n",
       " 'hi',\n",
       " 'hjs',\n",
       " 'his',\n",
       " 'hi',\n",
       " 'hs',\n",
       " 'his',\n",
       " 'hjsss',\n",
       " 'ip',\n",
       " 'hi',\n",
       " 'hs',\n",
       " 'hgh',\n",
       " 'hiisv',\n",
       " 'his',\n",
       " 'his',\n",
       " 'his',\n",
       " 'hiss',\n",
       " 't',\n",
       " 'his',\n",
       " 'hir',\n",
       " 'hi',\n",
       " 'his',\n",
       " 'fgit',\n",
       " 'his',\n",
       " 'ii',\n",
       " 'his',\n",
       " 'his',\n",
       " 'his',\n",
       " 'hs',\n",
       " 'is',\n",
       " 'is',\n",
       " 'i',\n",
       " 'his',\n",
       " 'hs',\n",
       " 'hiis',\n",
       " 'hi',\n",
       " 'hgs',\n",
       " 'hht',\n",
       " 'ii',\n",
       " 'his',\n",
       " 'hi',\n",
       " 'hi',\n",
       " 'hs',\n",
       " 'hs',\n",
       " 'hi',\n",
       " 's',\n",
       " 'hhis',\n",
       " 'is',\n",
       " 'his',\n",
       " 'his',\n",
       " 'h',\n",
       " 'is',\n",
       " 'his',\n",
       " 'his',\n",
       " 'hhis',\n",
       " 'hks',\n",
       " 'his',\n",
       " 'hiis',\n",
       " 'h',\n",
       " 'his',\n",
       " 'is',\n",
       " 'his',\n",
       " 'hi',\n",
       " 'ss',\n",
       " 'i',\n",
       " 'his',\n",
       " 'his',\n",
       " 'hjs',\n",
       " 'his',\n",
       " 'his',\n",
       " 'his',\n",
       " 'ir',\n",
       " 'his',\n",
       " 'hiiss',\n",
       " 'kis',\n",
       " 'ft',\n",
       " 'his',\n",
       " 'his',\n",
       " 'his',\n",
       " 'hs',\n",
       " 'hi',\n",
       " 'hs',\n",
       " 'hi',\n",
       " 'hi',\n",
       " 'his',\n",
       " 'hh',\n",
       " 'ss',\n",
       " 'hiis',\n",
       " 'h',\n",
       " 'hhs',\n",
       " 'hi',\n",
       " 'is',\n",
       " 'hhii',\n",
       " 'hi',\n",
       " 'ss',\n",
       " 'is',\n",
       " 'hjs',\n",
       " 'hit',\n",
       " 'hirt',\n",
       " 'hiis',\n",
       " 'his',\n",
       " 'his',\n",
       " 'hi',\n",
       " 'hhis',\n",
       " 'i',\n",
       " 'hi',\n",
       " 'hii',\n",
       " 'hhi',\n",
       " 'hs',\n",
       " 'hhi',\n",
       " 'h',\n",
       " 'hs',\n",
       " 'iis',\n",
       " 's',\n",
       " 'hs',\n",
       " 'hiss',\n",
       " 'hs',\n",
       " 'hhiis',\n",
       " 'hhis',\n",
       " 'ghks',\n",
       " 'hi',\n",
       " 'his',\n",
       " 'hs',\n",
       " 'iis',\n",
       " 'his',\n",
       " 'hit',\n",
       " 'hs',\n",
       " 'ks',\n",
       " 'hii',\n",
       " 'hs',\n",
       " 'hhis',\n",
       " 'hiv',\n",
       " 'hir',\n",
       " 'his',\n",
       " 'hi',\n",
       " 'hhis',\n",
       " 'hju',\n",
       " 'is',\n",
       " 'his',\n",
       " 'hi',\n",
       " 'iss',\n",
       " 'ip',\n",
       " 'is',\n",
       " 'is',\n",
       " 'fiss',\n",
       " 'his',\n",
       " 'is',\n",
       " 'i',\n",
       " 'hhiss',\n",
       " 'his',\n",
       " 'hiss',\n",
       " 'hi',\n",
       " 'hir',\n",
       " 'his',\n",
       " 'hmg',\n",
       " 'hhi',\n",
       " 'hs',\n",
       " 'hiiis',\n",
       " 'his',\n",
       " 'hs',\n",
       " 'i',\n",
       " 'h',\n",
       " 'hhs',\n",
       " 'hs',\n",
       " 'his',\n",
       " 's',\n",
       " 'his',\n",
       " 'ikss',\n",
       " 'hs',\n",
       " 'hhis',\n",
       " 'giss',\n",
       " 'his',\n",
       " 'is',\n",
       " 'his',\n",
       " 'hs',\n",
       " 'i',\n",
       " 'hi',\n",
       " 'is',\n",
       " 'his',\n",
       " 'fit',\n",
       " 'h',\n",
       " 'ghs',\n",
       " 'hi',\n",
       " 'hii',\n",
       " 'issss',\n",
       " 'hiss',\n",
       " 'his',\n",
       " 'hs',\n",
       " 'h',\n",
       " 'is',\n",
       " 'hi',\n",
       " 'hi',\n",
       " 'hs',\n",
       " 'is',\n",
       " 'his',\n",
       " 'i',\n",
       " 'his',\n",
       " 'hjs',\n",
       " 'ir',\n",
       " 'hs',\n",
       " 'is',\n",
       " 'hhis',\n",
       " 'ir',\n",
       " 'kis',\n",
       " 'ir',\n",
       " 'ss',\n",
       " 'hr',\n",
       " 'ju',\n",
       " 'hs',\n",
       " 'his',\n",
       " 'hs',\n",
       " 's',\n",
       " 'hi',\n",
       " 'hhrs',\n",
       " 'hi',\n",
       " 'h',\n",
       " 'ss',\n",
       " 'his',\n",
       " 'hs',\n",
       " 'hiiss',\n",
       " 'gis',\n",
       " 'is',\n",
       " 'hs',\n",
       " 'h',\n",
       " 'hisr',\n",
       " 'hiis',\n",
       " 'hhiis',\n",
       " 'is',\n",
       " 'is',\n",
       " 'is',\n",
       " 'hs',\n",
       " 'his',\n",
       " 'hiis',\n",
       " 'iss',\n",
       " 'his',\n",
       " 'i',\n",
       " 'his',\n",
       " 'h',\n",
       " 'his',\n",
       " 'hiq',\n",
       " 'hhiiis',\n",
       " 's',\n",
       " 'his',\n",
       " 'h',\n",
       " 'his',\n",
       " 'hi',\n",
       " 'his',\n",
       " 's',\n",
       " 'hht',\n",
       " 'hi',\n",
       " 'hi',\n",
       " 'iihq',\n",
       " 'hs',\n",
       " 'hi',\n",
       " 'hit',\n",
       " 's',\n",
       " 'his',\n",
       " 'hit',\n",
       " 'his',\n",
       " 'hv',\n",
       " 'gs',\n",
       " 'his',\n",
       " 'hhhis',\n",
       " 'iis',\n",
       " 'hi',\n",
       " 'his',\n",
       " 'hs',\n",
       " 'is',\n",
       " 'is',\n",
       " 'hi',\n",
       " 'hhiiss',\n",
       " 'hhts',\n",
       " 'iis',\n",
       " 's',\n",
       " 'iis',\n",
       " 'hs',\n",
       " 'hks',\n",
       " 'is',\n",
       " 'his',\n",
       " 'his',\n",
       " 'hjrs',\n",
       " 'his',\n",
       " 'hs',\n",
       " 'his',\n",
       " 'his',\n",
       " 'his',\n",
       " 'is',\n",
       " 'hiss',\n",
       " 'his',\n",
       " 'i',\n",
       " 'it',\n",
       " 'hi',\n",
       " 'his',\n",
       " 'hr',\n",
       " 'hs',\n",
       " 'hs',\n",
       " 'hs',\n",
       " 'hs',\n",
       " 'hiss',\n",
       " 'hiv',\n",
       " 'is',\n",
       " 'h',\n",
       " 'hs',\n",
       " 'hiiis',\n",
       " 'hhiq',\n",
       " 'hhis',\n",
       " 'iis',\n",
       " 'hs',\n",
       " 'is',\n",
       " 'hs',\n",
       " 'his',\n",
       " 'hhs',\n",
       " 'hs',\n",
       " 'hs',\n",
       " 'i',\n",
       " 'hi',\n",
       " 'his',\n",
       " 'his',\n",
       " 'his',\n",
       " 'his',\n",
       " 's',\n",
       " 'hs',\n",
       " 'it',\n",
       " 'hhhi',\n",
       " 'ggs',\n",
       " 'hhr',\n",
       " 'his',\n",
       " 'his',\n",
       " 'his',\n",
       " 'his',\n",
       " 'hs',\n",
       " 'hi',\n",
       " 'hs',\n",
       " 'his',\n",
       " 'his',\n",
       " 'hs',\n",
       " 'his',\n",
       " 'his',\n",
       " 'his',\n",
       " 'hhhis',\n",
       " 'hs',\n",
       " 'hit',\n",
       " 'his',\n",
       " 'hiis',\n",
       " 'his',\n",
       " 'hhiss',\n",
       " 'his',\n",
       " 'hii',\n",
       " 'hiq',\n",
       " 'his',\n",
       " 's',\n",
       " 'is',\n",
       " 'is',\n",
       " 'gs',\n",
       " 'i',\n",
       " 'his',\n",
       " 'hiis',\n",
       " 'his',\n",
       " 'hiq',\n",
       " 'is',\n",
       " 'js',\n",
       " 'hiiss',\n",
       " 'h',\n",
       " 'i',\n",
       " 'hiis',\n",
       " 'iii',\n",
       " 'gss',\n",
       " 'his',\n",
       " 'hjss',\n",
       " 'iss',\n",
       " 'hi',\n",
       " 'is',\n",
       " 'his',\n",
       " 'his',\n",
       " 'is',\n",
       " 'his',\n",
       " 'hs',\n",
       " 'ijs',\n",
       " 'is',\n",
       " 'i',\n",
       " 'h',\n",
       " 'hii',\n",
       " 'his',\n",
       " 'hs',\n",
       " 'is',\n",
       " 's',\n",
       " 'is',\n",
       " 'his',\n",
       " 'jis',\n",
       " 'hs',\n",
       " 'his',\n",
       " 'hi',\n",
       " 'is',\n",
       " 'is',\n",
       " 'hhhis',\n",
       " 'i',\n",
       " 'i',\n",
       " 'hir',\n",
       " 'hiss',\n",
       " 'is',\n",
       " 'hhiis',\n",
       " 'hs',\n",
       " 'his',\n",
       " 'hiis',\n",
       " 'hsss',\n",
       " 'hs',\n",
       " 'iis',\n",
       " 'hiss',\n",
       " 'hs',\n",
       " 'his',\n",
       " 'hi',\n",
       " 'hs',\n",
       " 'his',\n",
       " 'hhjs',\n",
       " 'his',\n",
       " 'is',\n",
       " 'gisrs',\n",
       " 'hs',\n",
       " 'his',\n",
       " 'hiir',\n",
       " 'i',\n",
       " 'is',\n",
       " 'hhss',\n",
       " 'hhs',\n",
       " 'his',\n",
       " 'hs',\n",
       " 'hgis',\n",
       " 'js',\n",
       " 'his',\n",
       " 'hs',\n",
       " 'his',\n",
       " 'hi',\n",
       " 'hi',\n",
       " 'hs',\n",
       " 'i',\n",
       " 'hs',\n",
       " 'hi',\n",
       " 'h',\n",
       " 'giiis',\n",
       " 'hhit',\n",
       " 'hjs',\n",
       " 'his',\n",
       " 'j',\n",
       " 'his',\n",
       " 'hms',\n",
       " 'his',\n",
       " 'hjs',\n",
       " 'his',\n",
       " 'hs',\n",
       " 'is',\n",
       " 's',\n",
       " 'hiss',\n",
       " 'his',\n",
       " 'hs',\n",
       " 'his',\n",
       " 'his',\n",
       " 'his',\n",
       " 'hs',\n",
       " 'fis',\n",
       " 'h',\n",
       " 'his',\n",
       " 'hs',\n",
       " 'hi',\n",
       " 'hs',\n",
       " 'ii',\n",
       " 'hq',\n",
       " 's',\n",
       " 'jit',\n",
       " 'hgss',\n",
       " 'his',\n",
       " 'iit',\n",
       " 'jiis',\n",
       " 'hii',\n",
       " 'hiss',\n",
       " 'jis',\n",
       " 'gs',\n",
       " 'hr',\n",
       " 'is',\n",
       " 'is',\n",
       " 'hi',\n",
       " 'his',\n",
       " 'hs',\n",
       " 'hiss',\n",
       " 'hjs',\n",
       " 'hir',\n",
       " 'hs',\n",
       " 'his',\n",
       " 'his',\n",
       " 'hs',\n",
       " 'hs',\n",
       " 'his',\n",
       " 'his',\n",
       " 'his',\n",
       " 'is',\n",
       " 'hv',\n",
       " 'is',\n",
       " ...]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See the result of typing the same word 10000 times\n",
    "[typeOneWord(word, False) for i in range(10000) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Basics of file input/output in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Basics of file output in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write data into a file. \n",
    "Lines = [\"Line 1: a;\",\"Line 2: b;\",\"Line 3: c;\"]\n",
    "\n",
    "file = open(\"outputFile1\",\"w\") \n",
    "for L in Lines:\n",
    "    file.write(L) \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load outputFile1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write data into a file. \n",
    "Lines = [\"Line 1: a;\",\"Line 2: b;\",\"Line 3: c;\"]\n",
    "\n",
    "file = open(\"outputFile2\",\"w\") \n",
    "file.writelines(Lines) \n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load outputFile2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write data into a file. \n",
    "Lines = [\"Line 1: a;\",\"Line 2: b;\",\"Line 3: c;\"]\n",
    "\n",
    "file = open(\"outputFile3\",\"w\") \n",
    "for line in Lines:\n",
    "    file.writelines(line +\"\\n\") \n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load outputFile3\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Basics of file intput in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x is Line 1: a;\n",
      "Line 2: b;\n",
      "Line 3: c;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read data from a file. \n",
    "file = open(\"outputFile3\",\"r\") \n",
    "x=file.read()\n",
    "print(\"x is\", x)\n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Line 1: a;\\n', 'Line 2: b;\\n', 'Line 3: c;\\n')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open(\"outputFile3\",\"r\") \n",
    "x=file.readline()\n",
    "y=file.readline()\n",
    "z=file.readline()\n",
    "#show what we got in x, y, z\n",
    "x, y, z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lines is ['Line 1: a;\\n', 'Line 2: b;\\n', 'Line 3: c;\\n']\n"
     ]
    }
   ],
   "source": [
    "file = open(\"outputFile3\",\"r\") \n",
    "lines=file.readlines()\n",
    "print(\"lines is\", lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Line 1: a;', 'Line 2: b;', 'Line 3: c;']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Strip the white spaces(i.e. spaces, tabs, and specifically'\\n' in this case)\n",
    "strippedLines = [line.strip( ) for line in lines]\n",
    "strippedLines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72  words in biolaVision.txt:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['biola',\n",
       " 'university',\n",
       " 'vision',\n",
       " 'is',\n",
       " 'to',\n",
       " 'be',\n",
       " 'an',\n",
       " 'exemplary',\n",
       " 'christian',\n",
       " 'university',\n",
       " 'characterized',\n",
       " 'as',\n",
       " 'a',\n",
       " 'community',\n",
       " 'of',\n",
       " 'grace',\n",
       " 'that',\n",
       " 'promotes',\n",
       " 'and',\n",
       " 'inspires',\n",
       " 'personal',\n",
       " 'life',\n",
       " 'transformation',\n",
       " 'in',\n",
       " 'christ',\n",
       " 'which',\n",
       " 'illuminates',\n",
       " 'the',\n",
       " 'world',\n",
       " 'with',\n",
       " 'his',\n",
       " 'light',\n",
       " 'and',\n",
       " 'truth',\n",
       " 'further',\n",
       " 'as',\n",
       " 'a',\n",
       " 'global',\n",
       " 'center',\n",
       " 'for',\n",
       " 'christian',\n",
       " 'thought',\n",
       " 'and',\n",
       " 'an',\n",
       " 'influential',\n",
       " 'evangelical',\n",
       " 'voice',\n",
       " 'that',\n",
       " 'addresses',\n",
       " 'crucial',\n",
       " 'cultural',\n",
       " 'issues',\n",
       " 'biola',\n",
       " 'university',\n",
       " 'aspires',\n",
       " 'to',\n",
       " 'lead',\n",
       " 'with',\n",
       " 'confidence',\n",
       " 'and',\n",
       " 'compassion',\n",
       " 'an',\n",
       " 'intellectual',\n",
       " 'and',\n",
       " 'spiritual',\n",
       " 'renewal',\n",
       " 'that',\n",
       " 'advances',\n",
       " 'the',\n",
       " 'purpose',\n",
       " 'of',\n",
       " 'christ']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read words from biolaVision.txt\n",
    "file = open(\"biolaVision.txt\",\"r\") \n",
    "lines = file.readlines()\n",
    "file.close()\n",
    "\n",
    "words = [line.strip( ) for line in lines]\n",
    "\n",
    "print(len(words), \" words in biolaVision.txt:\\n\")\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Implement typeOneArticle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C++: void typeOneArticle (const char * corruptedMessageFile, const char * sourceArticle, \n",
    "#                           bool trace = false);\n",
    "# Or\n",
    "# C++: void typeOneArticle (const string corruptedMessageFile, const string sourceArticle, \n",
    "#                           bool trace = false);\n",
    "# ==>\n",
    "# Python: typeOneArticle (corruptedMessageFile, sourceArticle, \n",
    "#                           trace = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def typeOneArticle(corruptedMessageFile, sourceArticle, trace = False):\n",
    "    file = open(sourceArticle,\"r\") \n",
    "    lines = file.readlines()\n",
    "    file.close()\n",
    "    words = [line.strip( ) for line in lines]\n",
    "    \n",
    "    corruptedWords = [ typeOneWord(word) for word in words]\n",
    "    if trace:\n",
    "        print( corruptedWords )\n",
    "    \n",
    "    file = open(corruptedMessageFile,\"w\") \n",
    "    for corruptedWord in corruptedWords:\n",
    "        file.writelines(corruptedWord+\"\\n\")\n",
    "    file.close()\n",
    "    \n",
    "                        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_hit = 0.6\n",
    "pr_miss = 0.4\n",
    "deg_kb = 2\n",
    "\n",
    "pr_repeat = 0.2\n",
    "pr_moveOn = 0.8\n",
    "deg_sp = 2\n",
    "\n",
    "typeOneArticle(\"corruptedVision\", \"biolaVision.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load corruptedVision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Program 3A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordToType = \"his\"\n",
    "observedString = \"he\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State representations (excluding the special state I and F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_indicices = list( range(len(wordToType) ))\n",
    "state_indicices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'his'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_chars = wordToType\n",
    "state_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'h'), (1, 'i'), (2, 's')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states = [ (state_index, state_char) for state_index, state_char in zip(  state_indicices, state_chars)]\n",
    "states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HMM representation (excluding the special state I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5714285714285714, 0.2857142857142857, 0.14285714285714285]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#At the beginning, the initial probability vector Pi after leaving the special state I\n",
    "\n",
    "vector_pi_list = getPrTableForPossibleInitialStatesGivenTheWord(wordToType)\n",
    "vector_pi_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.2, 0.4571428571428572, 0.2285714285714286, 0.1142857142857143],\n",
       " [0.0, 0.2, 0.5333333333333333, 0.26666666666666666],\n",
       " [0.0, 0.0, 0.2, 0.8]]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transition probability matrix A (excluding the rows and columns for I and F)\n",
    "lenthOfWord = len(wordToType)\n",
    "matrix_A_List = [ getPrTableForPossibleNextStatesGivenWord(wordToType, currentState) for currentState in range(lenthOfWord)]\n",
    "matrix_A_List "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4571428571428572"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access the transition probability $a_{ij}$\n",
    "i = 0; j =1\n",
    "matrix_A_List[i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.001562786154691411,\n",
       "  0.003125572309382822,\n",
       "  0.006251144618765644,\n",
       "  0.012502289237531288,\n",
       "  0.025004578475062576,\n",
       "  0.05000915695012515,\n",
       "  0.1000183139002503,\n",
       "  0.6,\n",
       "  0.1000183139002503,\n",
       "  0.05000915695012515,\n",
       "  0.025004578475062576,\n",
       "  0.012502289237531288,\n",
       "  0.006251144618765644,\n",
       "  0.003125572309382822,\n",
       "  0.001562786154691411,\n",
       "  0.0007813930773457055,\n",
       "  0.00039069653867285274,\n",
       "  0.00019534826933642637,\n",
       "  9.767413466821319e-05,\n",
       "  4.883706733410659e-05,\n",
       "  2.4418533667053296e-05,\n",
       "  4.883706733410659e-05,\n",
       "  9.767413466821319e-05,\n",
       "  0.00019534826933642637,\n",
       "  0.00039069653867285274,\n",
       "  0.0007813930773457055],\n",
       " [0.0007813930773457055,\n",
       "  0.001562786154691411,\n",
       "  0.003125572309382822,\n",
       "  0.006251144618765644,\n",
       "  0.012502289237531288,\n",
       "  0.025004578475062576,\n",
       "  0.05000915695012515,\n",
       "  0.1000183139002503,\n",
       "  0.6,\n",
       "  0.1000183139002503,\n",
       "  0.05000915695012515,\n",
       "  0.025004578475062576,\n",
       "  0.012502289237531288,\n",
       "  0.006251144618765644,\n",
       "  0.003125572309382822,\n",
       "  0.001562786154691411,\n",
       "  0.0007813930773457055,\n",
       "  0.00039069653867285274,\n",
       "  0.00019534826933642637,\n",
       "  9.767413466821319e-05,\n",
       "  4.883706733410659e-05,\n",
       "  2.4418533667053296e-05,\n",
       "  4.883706733410659e-05,\n",
       "  9.767413466821319e-05,\n",
       "  0.00019534826933642637,\n",
       "  0.00039069653867285274],\n",
       " [0.0007813930773457055,\n",
       "  0.00039069653867285274,\n",
       "  0.00019534826933642637,\n",
       "  9.767413466821319e-05,\n",
       "  4.883706733410659e-05,\n",
       "  2.4418533667053296e-05,\n",
       "  4.883706733410659e-05,\n",
       "  9.767413466821319e-05,\n",
       "  0.00019534826933642637,\n",
       "  0.00039069653867285274,\n",
       "  0.0007813930773457055,\n",
       "  0.001562786154691411,\n",
       "  0.003125572309382822,\n",
       "  0.006251144618765644,\n",
       "  0.012502289237531288,\n",
       "  0.025004578475062576,\n",
       "  0.05000915695012515,\n",
       "  0.1000183139002503,\n",
       "  0.6,\n",
       "  0.1000183139002503,\n",
       "  0.05000915695012515,\n",
       "  0.025004578475062576,\n",
       "  0.012502289237531288,\n",
       "  0.006251144618765644,\n",
       "  0.003125572309382822,\n",
       "  0.001562786154691411]]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# observation probability matrix B, \n",
    "# excluding the rows for I and F columns, \n",
    "# exclucing the columns for ReadyToType and EndOfWord\n",
    "alphabet = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "matrix_B_List = [ [prCharGiveCharState(char, state_Char) for char in alphabet] \n",
    "                  for state_Char in state_chars]\n",
    "matrix_B_List "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001562786154691411"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access the observation probability $b_{ij}$\n",
    "i = 0; j =0   #Typing the first character (state_index is 0) in the word but get 'a' generated  \n",
    "matrix_B_List[i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.003125572309382822"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access the observation probability $b_{ij}$\n",
    "i = 0; j =1   #Typing the first character (state_index is 0) in the word but get 'b' generated   \n",
    "matrix_B_List[i][j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use np arrays as data structures instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_pi = np.array( vector_pi_list )\n",
    "matrix_A = np.array( matrix_A_List )\n",
    "matrix_B = np.array( matrix_B_List )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.57142857 0.28571429 0.14285714]\n",
      "(3,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(vector_pi)  #Check the shape\n",
    "print(vector_pi.shape)  #Check the shape\n",
    "vector_pi.sum()         #Check the sum of probabilties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1.])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(matrix_A.shape)  #Check the shape\n",
    "matrix_A.sum(axis = 1) #Check the sum of probabilties on each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 26)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1.])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(matrix_B.shape)  #Check the shape\n",
    "matrix_B.sum(axis = 1) #Check the sum of probabilties on each row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: You can use lists above as the data structures to implement the work or You may consider using numpy arrays as the data structures to implement the work. Below shows the idea of using Numpy arrays for the implementation of the forward algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordToType = \"his\"\n",
    "observedString = \"ab\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1 (The column for observing ReadyToType ): Must start at state I (probability 0 for the other states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2 (The column for observing 'a'): only keep the real states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.57142857, 0.28571429, 0.14285714])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Probabilties of transitioning into each of the real states from I\n",
    "print( vector_pi.shape)\n",
    "vector_pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Probabilties of transitioning into each of the real states from I\n",
    "stage2_1 = vector_pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "charObserved: a\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.00156279, 0.00078139, 0.00078139])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Probabilities of observing the first character in each of the real states (excluding F)\n",
    "observationIndex = 0\n",
    "charObserved = observedString[observationIndex]\n",
    "print( \"charObserved:\", charObserved)\n",
    "indexOfObservedChar = ord(charObserved) - ord('a')\n",
    "matrix_B[:, indexOfObservedChar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00089302, 0.00022326, 0.00011163])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine the two items above to calculate\n",
    "# Probabilities of ending in each of the real states (excluding F) and observing a\n",
    "stage2_2 = stage2_1*matrix_B[:, indexOfObservedChar]\n",
    "stage2_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 3 (The column for observing 'b'): only keep the real states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00089302, 0.00022326, 0.00011163])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stage2_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00089302],\n",
       "       [0.00022326],\n",
       "       [0.00011163]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stage2_2[:, np.newaxis]\n",
    "print( stage2_2[:, np.newaxis].shape )\n",
    "stage2_2[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.78604132e-04, 4.08238016e-04, 2.04119008e-04, 1.02059504e-04],\n",
       "       [0.00000000e+00, 4.46510330e-05, 1.19069421e-04, 5.95347107e-05],\n",
       "       [0.00000000e+00, 0.00000000e+00, 2.23255165e-05, 8.93020660e-05]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Probabilties of further transitioning into each of the real states\n",
    "stage3_1 = stage2_2[:, np.newaxis]  * matrix_A\n",
    "stage3_1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0001786 , 0.00045289, 0.00034551, 0.0002509 ])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stage3_2 = stage3_1.sum(axis = 0)\n",
    "stage3_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0001786 , 0.00045289, 0.00034551])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Probabilities of ending in each of the real states (excluding F)\n",
    "stage3_2[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "charObserved: b\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.00312557, 0.00156279, 0.0003907 ])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Probabilities of observing the second character in each of the real states (excluding F)\n",
    "observationIndex = 1\n",
    "charObserved = observedString[observationIndex]\n",
    "print( \"charObserved:\", charObserved)\n",
    "indexOfObservedChar = ord(charObserved) - ord('a')\n",
    "matrix_B[:, indexOfObservedChar]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.58240129e-07, 7.07768735e-07, 1.34991103e-07])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine the two items above to calculate\n",
    "# Probabilities of ending in each of the real states (excluding F) and observing b\n",
    "stage3_3 = stage3_2[:-1]*matrix_B[:, indexOfObservedChar]\n",
    "stage3_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 4 (The column for observing EndOfWord ): Must be in the Final State F (probability = 0 for the other states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.58240129e-07, 7.07768735e-07, 1.34991103e-07])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probabilities of ending in each of the real states (excluding F) and observing b\n",
    "stage3_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.11428571, 0.26666667, 0.8       ])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probabilities of then transitioning to F from each of the real states\n",
    "matrix_A[:, len( wordToType)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.37988719e-08, 1.88738329e-07, 1.07992882e-07])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine the two items above to calculate the\n",
    "# Probabilities of then transition to F and ending the typing process of the word\n",
    "# Transisiton to F (index 3 in this case )\n",
    "stage4_1 = stage3_3 * matrix_A[:, len( wordToType)]\n",
    "stage4_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The result is the sum of all these probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.6053008344833416e-07"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = stage4_1.sum()\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The result above is also what you would get from the sample demo program for HMMs.\n",
    "# * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Program 3A_Complete ==> \n",
    "## 1. Define a function prOf1CharSeriesWhenTyping1Word_F to generalize the process (of the forward algorithm) demonstrated in the case above for any given wordToType and any given observedString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the forward algorithm algorithm to determine the probability: \n",
    "# The function should calculate and return\n",
    "#     the probability of getting the string d \n",
    "#     when the user (modelled by the parameter values of pr_hit, pr_repeat, degenerate_kb, ...)\n",
    "#     want to type the word in string w\n",
    "# When the trace is True, the function will report the trace of computation done.\n",
    "\n",
    "def prOf1CharSeriesWhenTyping1Word_F(observedString, wordToType, trace = False):\n",
    "    #The probability distribution after leaving I\n",
    "    vector_pi_list = getPrTableForPossibleInitialStatesGivenTheWord(wordToType)\n",
    "    \n",
    "    #The transition probability matrix A\n",
    "    lenthOfWord = len(wordToType)\n",
    "    matrix_A_List = [ getPrTableForPossibleNextStatesGivenWord(wordToType, currentState) \n",
    "                      for currentState in range(lenthOfWord)]\n",
    "    \n",
    "    #The observation probability matrix B\n",
    "    alphabet = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "    matrix_B_List = [ [prCharGiveCharState(char, state_Char) for char in alphabet] \n",
    "                      for state_Char in wordToType]\n",
    "    \n",
    "    ##############################################\n",
    "    #Cast them into numpy arrays\n",
    "    ##############################################\n",
    "    vector_pi = np.array( vector_pi_list )\n",
    "    matrix_A = np.array( matrix_A_List )\n",
    "    matrix_B = np.array( matrix_B_List )\n",
    "    \n",
    "    if trace == True:\n",
    "        print(\"vector_pi\", vector_pi.shape, \":\\n\", vector_pi)\n",
    "        print(\"matrix_A\", matrix_A.shape, \":\\n\", matrix_A)\n",
    "        print(\"matrix_B\", matrix_B.shape, \":\\n\", matrix_B)\n",
    "    \n",
    "    ##############################################\n",
    "    #For the first column (corresponding to the first character observed)\n",
    "    ##############################################\n",
    "    observationIndex = 0\n",
    "    charObserved = observedString[observationIndex]\n",
    "    if trace == True:\n",
    "        print( \"\\n\\nobservationIndex, charObserved:\", observationIndex, \",\", charObserved)\n",
    "    indexOfObservedCharInAlphabet = ord(charObserved) - ord('a');\n",
    "    \n",
    "    #transitionProbabilties record the 1st-stage results of a column regarding \n",
    "    #    the probabilities of ending in each of the states at this point\n",
    "    transitionProbabilties = vector_pi\n",
    "    if trace == True:\n",
    "        print(\"Probabilties of ending at the states at this point:\\n\", transitionProbabilties)\n",
    "    \n",
    "    #columnProbabilities record the 2nd-stage results of a column regarding \n",
    "    #    the probabilities of ending in each of the states at this point and also\n",
    "    #                         seeing the specific character at this point\n",
    "    observationProbabilities = matrix_B[:, indexOfObservedCharInAlphabet]\n",
    "    if trace == True:\n",
    "        print(\"probabilities of observing \", charObserved, \" at specific states alone:\\n\", \n",
    "              observationProbabilities)\n",
    "\n",
    "    columnProbabilities = transitionProbabilties * observationProbabilities\n",
    "    if trace == True:\n",
    "        print(\"Probabilties of observing up to\", charObserved, \n",
    "              \" and ending at the states at this point:\\n\", columnProbabilities)\n",
    "    \n",
    "    \n",
    "    ##############################################\n",
    "    # For the remaining columns one at a time\n",
    "    ##############################################\n",
    "    lenthOfObservedString = len(observedString)\n",
    "    for observationIndex in np.arange(1, lenthOfObservedString):\n",
    "        charObserved = observedString[observationIndex]\n",
    "        if trace == True:\n",
    "            print( \"\\nobservationIndex, charObserved:\", observationIndex, \",\", charObserved)\n",
    "        \n",
    "        transitionProbabilties = (columnProbabilities[:, np.newaxis] * matrix_A).sum(axis = 0)\n",
    "        transitionProbabilties = transitionProbabilties[:-1]  # Drop the probability to F\n",
    "        if trace == True:\n",
    "            print(\"Probabilties of ending at the states at this point:\\n\", transitionProbabilties)\n",
    "\n",
    "        indexOfObservedCharInAlphabet = ord(charObserved) - ord('a')\n",
    "        observationProbabilities = matrix_B[:, indexOfObservedCharInAlphabet]\n",
    "        if trace == True:\n",
    "            print(\"probabilities of observing \", charObserved, \" at specific states alone:\\n\", \n",
    "                  observationProbabilities)\n",
    "\n",
    "        columnProbabilities = (transitionProbabilties) * observationProbabilities\n",
    "        if trace == True:\n",
    "            print(\"Probabilties of observing up to\", charObserved, \n",
    "                  \" and ending at the states at this point:\\n\", columnProbabilities)\n",
    "    \n",
    "    ##############################################\n",
    "    # Determine the sum of probabilities of transitioning to the Final state F from each state\n",
    "    ##############################################\n",
    "    if trace == True:\n",
    "        print(\"\\nprobabilities of transitioning to F from states at this point:\\n\", \n",
    "              matrix_A[:, len( wordToType)] )\n",
    "    pr = (columnProbabilities * matrix_A[:, len( wordToType)]).sum()\n",
    "    if trace == True:\n",
    "        print(\"\\nSum of the probabilitie above:\", pr);\n",
    "    \n",
    "    return pr \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector_pi (3,) :\n",
      " [0.57142857 0.28571429 0.14285714]\n",
      "matrix_A (3, 4) :\n",
      " [[0.2        0.45714286 0.22857143 0.11428571]\n",
      " [0.         0.2        0.53333333 0.26666667]\n",
      " [0.         0.         0.2        0.8       ]]\n",
      "matrix_B (3, 26) :\n",
      " [[1.56278615e-03 3.12557231e-03 6.25114462e-03 1.25022892e-02\n",
      "  2.50045785e-02 5.00091570e-02 1.00018314e-01 6.00000000e-01\n",
      "  1.00018314e-01 5.00091570e-02 2.50045785e-02 1.25022892e-02\n",
      "  6.25114462e-03 3.12557231e-03 1.56278615e-03 7.81393077e-04\n",
      "  3.90696539e-04 1.95348269e-04 9.76741347e-05 4.88370673e-05\n",
      "  2.44185337e-05 4.88370673e-05 9.76741347e-05 1.95348269e-04\n",
      "  3.90696539e-04 7.81393077e-04]\n",
      " [7.81393077e-04 1.56278615e-03 3.12557231e-03 6.25114462e-03\n",
      "  1.25022892e-02 2.50045785e-02 5.00091570e-02 1.00018314e-01\n",
      "  6.00000000e-01 1.00018314e-01 5.00091570e-02 2.50045785e-02\n",
      "  1.25022892e-02 6.25114462e-03 3.12557231e-03 1.56278615e-03\n",
      "  7.81393077e-04 3.90696539e-04 1.95348269e-04 9.76741347e-05\n",
      "  4.88370673e-05 2.44185337e-05 4.88370673e-05 9.76741347e-05\n",
      "  1.95348269e-04 3.90696539e-04]\n",
      " [7.81393077e-04 3.90696539e-04 1.95348269e-04 9.76741347e-05\n",
      "  4.88370673e-05 2.44185337e-05 4.88370673e-05 9.76741347e-05\n",
      "  1.95348269e-04 3.90696539e-04 7.81393077e-04 1.56278615e-03\n",
      "  3.12557231e-03 6.25114462e-03 1.25022892e-02 2.50045785e-02\n",
      "  5.00091570e-02 1.00018314e-01 6.00000000e-01 1.00018314e-01\n",
      "  5.00091570e-02 2.50045785e-02 1.25022892e-02 6.25114462e-03\n",
      "  3.12557231e-03 1.56278615e-03]]\n",
      "\n",
      "\n",
      "observationIndex, charObserved: 0 , h\n",
      "Probabilties of ending at the states at this point:\n",
      " [0.57142857 0.28571429 0.14285714]\n",
      "probabilities of observing  h  at specific states alone:\n",
      " [6.00000000e-01 1.00018314e-01 9.76741347e-05]\n",
      "Probabilties of observing up to h  and ending at the states at this point:\n",
      " [3.42857143e-01 2.85766611e-02 1.39534478e-05]\n",
      "\n",
      "observationIndex, charObserved: 1 , i\n",
      "Probabilties of ending at the states at this point:\n",
      " [0.06857143 0.16245003 0.09361102]\n",
      "probabilities of observing  i  at specific states alone:\n",
      " [1.00018314e-01 6.00000000e-01 1.95348269e-04]\n",
      "Probabilties of observing up to i  and ending at the states at this point:\n",
      " [6.85839867e-03 9.74700157e-02 1.82867514e-05]\n",
      "\n",
      "observationIndex, charObserved: 2 , s\n",
      "Probabilties of ending at the states at this point:\n",
      " [0.00137168 0.02262927 0.0535553 ]\n",
      "probabilities of observing  s  at specific states alone:\n",
      " [9.76741347e-05 1.95348269e-04 6.00000000e-01]\n",
      "Probabilties of observing up to s  and ending at the states at this point:\n",
      " [1.33977631e-07 4.42058894e-06 3.21331798e-02]\n",
      "\n",
      "probabilities of transitioning to F from states at this point:\n",
      " [0.11428571 0.26666667 0.8       ]\n",
      "\n",
      "Sum of the probabilitie above: 0.02570773798355381\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.02570773798355381"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With trace\n",
    "prOf1CharSeriesWhenTyping1Word_F(\"his\", \"his\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02570773798355381"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No trace\n",
    "prOf1CharSeriesWhenTyping1Word_F(\"his\", \"his\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.180732321622022e-11"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prOf1CharSeriesWhenTyping1Word_F(\"sadasff\", \"parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define a function prOf1CharSeriesWhenTyping1Word_B to implement a brute-force version for any given wordToType and any given observedString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0]\n",
      "[0 1]\n",
      "[0 2]\n",
      "[0 3]\n",
      "[1 0]\n",
      "[1 1]\n",
      "[1 2]\n",
      "[1 3]\n",
      "[2 0]\n",
      "[2 1]\n",
      "[2 2]\n",
      "[2 3]\n",
      "[3 0]\n",
      "[3 1]\n",
      "[3 2]\n",
      "[3 3]\n"
     ]
    }
   ],
   "source": [
    "# A function to return the next state trajectory as a 1 dimensional numpy array\n",
    "def getNextTrajectory(currentTrajectory, sizeOfStateSpace, trace = False):\n",
    "    if np.any(currentTrajectory < sizeOfStateSpace-1) == False: \n",
    "         return np.zeros( currentTrajectory.shape[0] )\n",
    "    \n",
    "    incrementPoint = currentTrajectory.shape[0] -1\n",
    "    while currentTrajectory[incrementPoint] == sizeOfStateSpace-1:\n",
    "        incrementPoint -= 1\n",
    "    if trace: print(\"incrementPoint\", incrementPoint )\n",
    "    nextTrajectory  = currentTrajectory.copy()\n",
    "    nextTrajectory[ incrementPoint  ] += 1\n",
    "    nextTrajectory[ incrementPoint+1:  ] = 0\n",
    "    return nextTrajectory\n",
    "\n",
    "\n",
    "trajectory = np.array([0,0])\n",
    "print( trajectory )\n",
    "for i in np.arange(15):\n",
    "    trajectory = getNextTrajectory(trajectory, 4)\n",
    "    print( trajectory )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0]\n",
      "[0 0 1]\n",
      "[0 0 2]\n",
      "[0 0 3]\n",
      "[0 1 0]\n",
      "[0 1 1]\n",
      "[0 1 2]\n",
      "[0 1 3]\n",
      "[0 2 0]\n",
      "[0 2 1]\n",
      "[0 2 2]\n",
      "[0 2 3]\n",
      "[0 3 0]\n",
      "[0 3 1]\n",
      "[0 3 2]\n",
      "[0 3 3]\n",
      "[1 0 0]\n",
      "[1 0 1]\n",
      "[1 0 2]\n",
      "[1 0 3]\n",
      "[1 1 0]\n",
      "[1 1 1]\n",
      "[1 1 2]\n",
      "[1 1 3]\n",
      "[1 2 0]\n",
      "[1 2 1]\n",
      "[1 2 2]\n",
      "[1 2 3]\n",
      "[1 3 0]\n",
      "[1 3 1]\n",
      "[1 3 2]\n",
      "[1 3 3]\n",
      "[2 0 0]\n",
      "[2 0 1]\n",
      "[2 0 2]\n",
      "[2 0 3]\n",
      "[2 1 0]\n",
      "[2 1 1]\n",
      "[2 1 2]\n",
      "[2 1 3]\n",
      "[2 2 0]\n",
      "[2 2 1]\n",
      "[2 2 2]\n",
      "[2 2 3]\n",
      "[2 3 0]\n",
      "[2 3 1]\n",
      "[2 3 2]\n",
      "[2 3 3]\n",
      "[3 0 0]\n",
      "[3 0 1]\n",
      "[3 0 2]\n",
      "[3 0 3]\n",
      "[3 1 0]\n",
      "[3 1 1]\n",
      "[3 1 2]\n",
      "[3 1 3]\n",
      "[3 2 0]\n",
      "[3 2 1]\n",
      "[3 2 2]\n",
      "[3 2 3]\n",
      "[3 3 0]\n",
      "[3 3 1]\n",
      "[3 3 2]\n",
      "[3 3 3]\n"
     ]
    }
   ],
   "source": [
    "# A more efficient variant of the function above:\n",
    "#   transformToNextTrajectory simply updates the contents of current trajectory\n",
    "#   to the next trajectory\n",
    "def transformToNextTrajectory_x(currentTrajectory, sizeOfStateSpace, trace = False):\n",
    "    if np.any(currentTrajectory < sizeOfStateSpace-1) == False: \n",
    "         return np.zeros( currentTrajectory.shape[0] )\n",
    "    \n",
    "    incrementPoint = currentTrajectory.shape[0] -1\n",
    "    while currentTrajectory[incrementPoint] == sizeOfStateSpace-1:\n",
    "        incrementPoint -= 1\n",
    "    if trace: print(\"incrementPoint\", incrementPoint )\n",
    "    currentTrajectory[ incrementPoint  ] += 1\n",
    "    currentTrajectory[ incrementPoint+1:  ] = 0\n",
    "\n",
    "\n",
    "\n",
    "sizeOfStateSpace = 4\n",
    "trajectory = np.array([0,0,0])\n",
    "print( trajectory )\n",
    "while np.all(trajectory == sizeOfStateSpace-1) == False:\n",
    "    transformToNextTrajectory_x(trajectory, sizeOfStateSpace)\n",
    "    print( trajectory )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0]\n",
      "[0 0 1]\n",
      "[0 0 2]\n",
      "[0 0 3]\n",
      "[0 1 1]\n",
      "[0 1 2]\n",
      "[0 1 3]\n",
      "[0 2 2]\n",
      "[0 2 3]\n",
      "[0 3 3]\n",
      "[1 1 1]\n",
      "[1 1 2]\n",
      "[1 1 3]\n",
      "[1 2 2]\n",
      "[1 2 3]\n",
      "[1 3 3]\n",
      "[2 2 2]\n",
      "[2 2 3]\n",
      "[2 3 3]\n",
      "[3 3 3]\n"
     ]
    }
   ],
   "source": [
    "# An even more efficient variant of the function above:\n",
    "#   only produce trajectories with non-decreasing state indices inside\n",
    "def transformToNextTrajectory(currentTrajectory, sizeOfStateSpace, trace = False):\n",
    "    if np.any(currentTrajectory < sizeOfStateSpace-1) == False: \n",
    "         return np.zeros( currentTrajectory.shape[0] )\n",
    "    \n",
    "    incrementPoint = currentTrajectory.shape[0] -1\n",
    "    while currentTrajectory[incrementPoint] == sizeOfStateSpace-1:\n",
    "        incrementPoint -= 1\n",
    "    if trace: print(\"incrementPoint\", incrementPoint )\n",
    "    currentTrajectory[ incrementPoint  ] += 1\n",
    "    currentTrajectory[ incrementPoint+1:  ] =  currentTrajectory[ incrementPoint  ]\n",
    "\n",
    "\n",
    "\n",
    "sizeOfStateSpace = 4\n",
    "trajectory = np.array([0,0,0])\n",
    "print( trajectory )\n",
    "while np.all(trajectory == sizeOfStateSpace-1) == False:\n",
    "    transformToNextTrajectory(trajectory, sizeOfStateSpace)\n",
    "    print( trajectory )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the brute-force algorithm to determine the probability: \n",
    "# The function should calculate and return\n",
    "#     the probability of getting the string d \n",
    "#     when the user (modelled by the parameter values of pr_hit, pr_repeat, degenerate_kb, ...)\n",
    "#     want to type the word in string w\n",
    "# When the trace is True, the function will report the trace of computation done.\n",
    "\n",
    "\n",
    "def prOf1CharSeriesWhenTyping1Word_B(observedString, wordToType, trace = False):\n",
    "    #The probability distribution after leaving I\n",
    "    vector_pi_list = getPrTableForPossibleInitialStatesGivenTheWord(wordToType)\n",
    "    \n",
    "    #The transition probability matrix A\n",
    "    lenthOfWord = len(wordToType)\n",
    "    matrix_A_List = [ getPrTableForPossibleNextStatesGivenWord(wordToType, currentState) \n",
    "                      for currentState in range(lenthOfWord)]\n",
    "    \n",
    "    #The observation probability matrix B\n",
    "    alphabet = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "    matrix_B_List = [ [prCharGiveCharState(char, state_Char) for char in alphabet] \n",
    "                      for state_Char in wordToType]\n",
    "    \n",
    "    ##############################################\n",
    "    #Cast them into numpy arrays\n",
    "    ##############################################\n",
    "    vector_pi = np.array( vector_pi_list )\n",
    "    matrix_A = np.array( matrix_A_List )\n",
    "    matrix_B = np.array( matrix_B_List )\n",
    "    \n",
    "    if trace == True:\n",
    "        print(\"vector_pi\", vector_pi.shape, \":\\n\", vector_pi)\n",
    "        print(\"matrix_A\", matrix_A.shape, \":\\n\", matrix_A)\n",
    "        print(\"matrix_B\", matrix_B.shape, \":\\n\", matrix_B)\n",
    "    \n",
    "    #The trajectory should have the same length of observedString.\n",
    "    #Let's start from [0, ..., 0]\n",
    "    sizeOfStateSpace = len( wordToType)\n",
    "    lengthOfTrajectory = len(observedString)\n",
    "    trajectory = np.zeros( lengthOfTrajectory, dtype=\"int32\" ) \n",
    "    pr = 0\n",
    "    \n",
    "    allTrajectoriesExamined = False \n",
    "    while( allTrajectoriesExamined == False):\n",
    "        currentStateIndex = trajectory[ 0 ]\n",
    "        if trace == True:\n",
    "            print(\"type(currentStateIndex )\", type(currentStateIndex ) )\n",
    "            print(\"currentStateIndex=\", currentStateIndex )\n",
    "            print(\"trajectory[ 0 ]=\", trajectory[ 0 ] )\n",
    "        prTrajectory = vector_pi[ currentStateIndex  ]\n",
    "\n",
    "        #Check each observation \n",
    "        for observationIndex in np.arange(0, len(observedString) ): \n",
    "            currentStateIndex = trajectory[ observationIndex ]     \n",
    "                \n",
    "            #Multiply the observation probability\n",
    "            charObserved = observedString[ observationIndex ]\n",
    "            observedCharIndex =  ord(charObserved) -  ord('a')\n",
    "            prTrajectory  *=  matrix_B[ currentStateIndex, observedCharIndex]\n",
    "\n",
    "            #Check whether it is the end of observation\n",
    "            if observationIndex == len(observedString)-1 : \n",
    "                nextStateIndex =  len( wordToType)      #the special final state F as the end\n",
    "            else:\n",
    "                nextStateIndex = trajectory[ observationIndex + 1]  # a regular next state\n",
    "\n",
    "            #Multiply the transition probability to the next state\n",
    "            prTrajectory  *=  matrix_A[ currentStateIndex, nextStateIndex]\n",
    "\n",
    "        #Add the probability of this trajectory and observation to the total probability pr\n",
    "        pr += prTrajectory\n",
    "        \n",
    "        transformToNextTrajectory(trajectory, sizeOfStateSpace)\n",
    "        if np.all(trajectory == (sizeOfStateSpace-1) ):\n",
    "            allTrajectoriesExamined = True\n",
    "    \n",
    "\n",
    "    \n",
    "    return pr \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.025707737931218794"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prOf1CharSeriesWhenTyping1Word_B(\"his\", \"his\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.3796480158574565e-27"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prOf1CharSeriesWhenTyping1Word_B(\"hsdfsrrerdr\", \"his\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prOf1CharSeriesWhenTyping1Word_B(\"paramdguers\", \"parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming 3B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logPrOfGettingDocument1WhenTypingDocument2(observedDocument, actualDocument):\n",
    "    file = open(actualDocument,\"r\") \n",
    "    lines = file.readlines()\n",
    "    file.close()\n",
    "    actualWords = [line.strip( ) for line in lines]\n",
    "\n",
    "    file = open(observedDocument,\"r\") \n",
    "    lines = file.readlines()\n",
    "    file.close()\n",
    "    observedWords = [line.strip( ) for line in lines]\n",
    "\n",
    "    p_list_e = [] #list for e standard based log of pr\n",
    "    p_list_10 = [] #list for 10 based log of pr\n",
    "    \n",
    "    np.seterr(divide = 'ignore') \n",
    "    for d,w in zip(observedWords, actualWords):\n",
    "        p_list_e.append(np.log(prOf1CharSeriesWhenTyping1Word_F(d,w)))\n",
    "        #p_list_10.append(np.log10(prOf1CharSeriesWhenTyping1Word_F(d,w)))\n",
    "        #print(np.log(prOf1CharSeriesWhenTyping1Word_F(d,w)))\n",
    "\n",
    "#     print(\"log Probability({} | {}) is\".format(observedDocument, actualDocument))    \n",
    "#     print(np.sum(p_list_e), \"using natural logarithm base e, or equivalently\") \n",
    "#     print(np.sum(p_list_10), \"using logarithm base 10\") \n",
    "    \n",
    "    return np.sum(p_list_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-514.2314866867631"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logPrOfGettingDocument1WhenTypingDocument2('A.txt', 'biolaVision.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-726.2596105160525"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_hit = 0.2\n",
    "pr_miss = 0.8\n",
    "logPrOfGettingDocument1WhenTypingDocument2('A.txt', 'biolaVision.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply the functions to the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up list for each person's setting {name: [pr_hit, pr_moveOn]}\n",
    "persons = {'Johnny':[0.9, 0.9], 'Winnie':[0.7, 0.9], 'Manny':[0.9, 0.7], 'Cathy':[0.7, 0.7]}\n",
    "persons['Johnny'][0]\n",
    "\n",
    "#set up list for txt file\n",
    "documents = ['A.txt', 'B.txt', 'C.txt', 'D.txt', 'E.txt', 'F.txt', 'G.txt', 'H.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************************\n",
      "log Probability(A.txt | person):\n",
      "\n",
      "person:  Johnny -439.54040468070366\n",
      "\n",
      "person:  Winnie -474.25511217689655\n",
      "\n",
      "person:  Manny -472.1358651513194\n",
      "\n",
      "person:  Cathy -507.0782637104097\n",
      "\n",
      "*****************************************************\n",
      "log Probability(B.txt | person):\n",
      "\n",
      "person:  Johnny -641.4025369739651\n",
      "\n",
      "person:  Winnie -612.5797385070729\n",
      "\n",
      "person:  Manny -670.7067379701123\n",
      "\n",
      "person:  Cathy -643.7515725892247\n",
      "\n",
      "*****************************************************\n",
      "log Probability(C.txt | person):\n",
      "\n",
      "person:  Johnny -699.6348485807366\n",
      "\n",
      "person:  Winnie -741.9446817984312\n",
      "\n",
      "person:  Manny -640.6010651341728\n",
      "\n",
      "person:  Cathy -685.8225115114947\n",
      "\n",
      "*****************************************************\n",
      "log Probability(D.txt | person):\n",
      "\n",
      "person:  Johnny -1063.5549122297623\n",
      "\n",
      "person:  Winnie -1009.3924249674285\n",
      "\n",
      "person:  Manny -976.0387872888255\n",
      "\n",
      "person:  Cathy -924.4600385213306\n",
      "\n",
      "*****************************************************\n",
      "log Probability(E.txt | person):\n",
      "\n",
      "person:  Johnny -931.3648640160924\n",
      "\n",
      "person:  Winnie -882.2002539475624\n",
      "\n",
      "person:  Manny -887.3323815003998\n",
      "\n",
      "person:  Cathy -841.4990901914261\n",
      "\n",
      "*****************************************************\n",
      "log Probability(F.txt | person):\n",
      "\n",
      "person:  Johnny -697.3311239291997\n",
      "\n",
      "person:  Winnie -739.2546513390957\n",
      "\n",
      "person:  Manny -641.9188791377683\n",
      "\n",
      "person:  Cathy -686.0554791862593\n",
      "\n",
      "*****************************************************\n",
      "log Probability(G.txt | person):\n",
      "\n",
      "person:  Johnny -633.2059107406496\n",
      "\n",
      "person:  Winnie -610.5605843654807\n",
      "\n",
      "person:  Manny -651.0236324573993\n",
      "\n",
      "person:  Cathy -631.4261809240514\n",
      "\n",
      "*****************************************************\n",
      "log Probability(H.txt | person):\n",
      "\n",
      "person:  Johnny -446.0231356821854\n",
      "\n",
      "person:  Winnie -475.88641223474076\n",
      "\n",
      "person:  Manny -473.5075378701134\n",
      "\n",
      "person:  Cathy -504.92036946575115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for document in documents:\n",
    "    print('*****************************************************')\n",
    "    print(\"log Probability({} | person):\\n\".format(document))\n",
    "    for person in persons:\n",
    "        pr_hit = persons[person][0]\n",
    "        pr_miss = round(1-pr_hit, 2)\n",
    "        pr_moveOn = persons[person][1]\n",
    "        pr_repeat = round(1-pr_moveOn, 2)\n",
    "\n",
    "        print('person: ', person, logPrOfGettingDocument1WhenTypingDocument2(document, 'biolaVision.txt'))\n",
    "        \n",
    "        print('')\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Program 4A Grid Search for Learing Parameter Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_hit_list = np.arange(0.1, 1.1, 0.1)\n",
    "pr_repeat_list = np.arange(0.1, 1.1, 0.1)\n",
    "pr_hit_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "deg_kb = 2\n",
    "deg_sp = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better parameter values found: maxLogPr improved => -841.4665839125322\n",
      "Better parameter values found: maxLogPr improved => -715.6256962942189\n",
      "Better parameter values found: maxLogPr improved => -637.4505112469527\n",
      "Better parameter values found: maxLogPr improved => -580.9249030864676\n",
      "Better parameter values found: maxLogPr improved => -537.202550895031\n",
      "Better parameter values found: maxLogPr improved => -502.2848775416399\n",
      "Better parameter values found: maxLogPr improved => -474.25511217689655\n",
      "Better parameter values found: maxLogPr improved => -452.6344298584175\n",
      "Better parameter values found: maxLogPr improved => -439.54040468070366\n",
      "\n",
      "Best parameter values found:\n",
      "\n",
      "Parameter values of the keyboard model:\n",
      "pr_hit = 0.9\n",
      "pr_miss = 0.1\n",
      "deg_kb = 2\n",
      "\n",
      "Parameter values of the spelling model:\n",
      "pr_repeat = 0.1\n",
      "pr_moveOn = 0.9\n",
      "deg_sp = 2\n"
     ]
    }
   ],
   "source": [
    "higher_prob = float('-inf')\n",
    "better_pr_hit = 0\n",
    "better_pr_repeat = 0\n",
    "for i in pr_hit_list:\n",
    "    for j in pr_repeat_list:\n",
    "        pr_hit = round(i, 2)\n",
    "        pr_miss = round(1-pr_hit, 2)\n",
    "        pr_repeat = round(j, 2)\n",
    "        pr_moveOn = round(1-pr_repeat, 2)\n",
    "\n",
    "        p = logPrOfGettingDocument1WhenTypingDocument2('A.txt', 'biolaVision.txt')\n",
    "        #print(pr_hit, pr_repeat)\n",
    "        if p > higher_prob:\n",
    "            higher_prob = p\n",
    "            better_pr_hit = round(i, 2)\n",
    "            better_pr_repeat = round(j, 2)\n",
    "            print('Better parameter values found: maxLogPr improved =>', higher_prob)\n",
    "            #print('\\t',better_pr_hit, better_pr_repeat)\n",
    "\n",
    "\n",
    "print('\\nBest parameter values found:')\n",
    "print('\\nParameter values of the keyboard model:')\n",
    "print('pr_hit =', better_pr_hit)\n",
    "print('pr_miss =', round(1-better_pr_hit, 2))\n",
    "print('deg_kb =', deg_kb)\n",
    "print('\\nParameter values of the spelling model:')\n",
    "print('pr_repeat =', better_pr_repeat)\n",
    "print('pr_moveOn =', round(1-better_pr_repeat, 2))\n",
    "print('deg_sp =', deg_sp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes about global variables in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y= 4\n",
      "x= 1\n"
     ]
    }
   ],
   "source": [
    "x = 1\n",
    "def f0():\n",
    "    y = x+3\n",
    "    print(\"y=\", y)\n",
    "\n",
    "f0()\n",
    "print(\"x=\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "x = 1\n",
    "def f1():\n",
    "    x = 0\n",
    "\n",
    "f1()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "x = 1\n",
    "def f2():\n",
    "    global x\n",
    "    x = 0\n",
    "\n",
    "f2()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def learnBestParameterValuesGivenDocument1WhenTypingDocument2(d,w, trace=False):\n",
    "    global pr_hit, pr_miss, pr_repeat, pr_moveOn             # Make them global variables\n",
    "    pr_hit_saved, pr_miss_saved = pr_hit, pr_miss            # Save values\n",
    "    pr_repeat_saved, pr_moveOn_saved = pr_repeat, pr_moveOn  # Save values\n",
    "    \n",
    "    pr_hit_list = np.linspace(0.1, 1.0, 10)\n",
    "    pr_repeat_list = np.linspace(0.1, 1.0, 10)\n",
    "    \n",
    "    higher_prob = np.NINF  #numpy negative infinity\n",
    "    better_pr_hit = 0\n",
    "    better_pr_repeat = 0\n",
    "    for pr_hit in pr_hit_list:\n",
    "        for pr_repeat in pr_repeat_list:\n",
    "            pr_miss = 1-pr_hit\n",
    "            pr_moveOn = 1-pr_repeat\n",
    "\n",
    "            p = logPrOfGettingDocument1WhenTypingDocument2(d, w)\n",
    "            if trace:\n",
    "                print(pr_hit, pr_repeat)\n",
    "                print(d, w)\n",
    "                print(p)\n",
    "            if p > higher_prob:\n",
    "                higher_prob = p\n",
    "                better_pr_hit = pr_hit\n",
    "                better_pr_repeat = pr_repeat\n",
    "                if trace:\n",
    "                    print('Better parameter values found: maxLogPr improved =>', higher_prob)\n",
    "\n",
    "\n",
    "    if trace:\n",
    "        print('\\nBest parameter values found:')\n",
    "        print('\\nParameter values of the keyboard model:')\n",
    "        print('pr_hit =', better_pr_hit)\n",
    "        print('pr_miss =', 1-better_pr_hit)\n",
    "        print('deg_kb =', deg_kb)\n",
    "        print('\\nParameter values of the spelling model:')\n",
    "        print('pr_repeat =', better_pr_repeat)\n",
    "        print('pr_moveOn =', 1-better_pr_repeat)\n",
    "        print('deg_sp =', deg_sp)\n",
    "        \n",
    "        \n",
    "    pr_hit, pr_miss = pr_hit_saved, pr_miss_saved              # Restore values\n",
    "    pr_repeat, pr_moveOn = pr_repeat_saved, pr_moveOn_saved    # Restore values\n",
    "\n",
    "        \n",
    "    return (better_pr_hit,1-better_pr_hit, better_pr_repeat, 1-better_pr_repeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9, 0.09999999999999998, 0.1, 0.9)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_hit, pr_miss, pr_repeat, pr_moveOn = 0.6, 0.4, 0.8, 0.2\n",
    "learnBestParameterValuesGivenDocument1WhenTypingDocument2('A.txt','biolaVision.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6, 0.4, 0.8, 0.2)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_hit, pr_miss, pr_repeat, pr_moveOn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7000000000000001, 0.29999999999999993, 0.1, 0.9)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learnBestParameterValuesGivenDocument1WhenTypingDocument2('B.txt','biolaVision.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6, 0.4, 0.8, 0.2)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_hit, pr_miss, pr_repeat, pr_moveOn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(0.1, 1.0, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Program 4B Gradient-Ascent Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learnBestParameterValuesGivenDocument1WhenTypingDocument2_GradientAscent(\n",
    "    d,w, stepSize = 0.01, trace=False):\n",
    "    global pr_hit, pr_miss, pr_repeat, pr_moveOn             # Make them global variables\n",
    "    pr_hit_saved, pr_miss_saved = pr_hit, pr_miss            # Save values\n",
    "    pr_repeat_saved, pr_moveOn_saved = pr_repeat, pr_moveOn  # Save values\n",
    "    \n",
    "    #Set a random starting point for the parameter values\n",
    "    pr_hit = np.random.rand() *0.6 + 0.2    #Make it starts in [0.2,0.8] \n",
    "    pr_repeat = np.random.rand() *0.6 + 0.2 #Make it starts in [0.2,0.8] \n",
    "    pr_miss = 1-pr_hit\n",
    "    pr_moveOn = 1-pr_repeat  \n",
    "    currentPr = logPrOfGettingDocument1WhenTypingDocument2(d, w)\n",
    "    \n",
    "    if trace:\n",
    "        print(\"pr_hit:\", pr_hit, \"  pr_repeat:\", pr_repeat)\n",
    "        print(\"Current logProbability = \", currentPr)\n",
    "        print(\"************************************\")\n",
    "    #Current performance of probability\n",
    "    \n",
    "    #Gradient-ascent search\n",
    "    keepSearching = True\n",
    "    while keepSearching:\n",
    "        #####################################\n",
    "        #Determine the gradient along pr_hit\n",
    "        #####################################\n",
    "        pr_hit_saved_2 = pr_hit      # Save the current pr_hit value\n",
    "        pr_hit = pr_hit + stepSize   # Move along pr_hit one step\n",
    "        pr_miss = 1 - pr_hit\n",
    "        #Check new performance of probability\n",
    "        newtPr = logPrOfGettingDocument1WhenTypingDocument2(d, w) \n",
    "        #Calculate the gradient component: a step along pr_hit \n",
    "        gradient_hit = newtPr - currentPr\n",
    "        pr_hit = pr_hit_saved_2      #Restore pr_hit\n",
    "        pr_miss = 1 - pr_hit         #Restore pr_miss\n",
    "        \n",
    "        #####################################\n",
    "        #Determine the gradient along pr_repeat\n",
    "        #####################################\n",
    "        pr_repeat_saved_2 = pr_repeat      # Save the current pr_repeat value\n",
    "        pr_repeat = pr_repeat + stepSize   # Move along pr_repeat one step\n",
    "        pr_moveOn = 1-pr_repeat\n",
    "        #Check new performance of probability\n",
    "        newtPr = logPrOfGettingDocument1WhenTypingDocument2(d, w) \n",
    "        #Calculate the gradient component: a step along pr_repeat \n",
    "        gradient_repeat = newtPr - currentPr\n",
    "        pr_repeat = pr_repeat_saved_2      #Restore pr_repeat\n",
    "        pr_moveOn = 1-pr_repeat            #Restore pr_moveOn\n",
    "\n",
    "        if trace:\n",
    "            print(\"gradient ==> \", gradient_hit, gradient_repeat)\n",
    "        \n",
    "        #####################################\n",
    "        #Move along the gradient \n",
    "        #####################################\n",
    "        learningRate = stepSize/np.sqrt(gradient_hit**2 + gradient_repeat**2)\n",
    "        \n",
    "        pr_hit = pr_hit + gradient_hit * learningRate\n",
    "        pr_repeat = pr_repeat + gradient_repeat * learningRate\n",
    "        pr_miss = 1-pr_hit\n",
    "        pr_moveOn = 1-pr_repeat  \n",
    "        \n",
    "        #Check new performance of probability\n",
    "        newtPr = logPrOfGettingDocument1WhenTypingDocument2(d, w)\n",
    "        improvement = newtPr - currentPr \n",
    "        if trace: \n",
    "            print(pr_hit, pr_repeat, \"==> logProbability = \", newtPr)\n",
    "\n",
    "        if improvement >= 0.00000001:\n",
    "            currentPr = newtPr   \n",
    "\n",
    "        if improvement <  0.00000001:\n",
    "            keepSearching = False\n",
    "            pr_hit = pr_hit_saved_2       #Restore the last parameter value\n",
    "            pr_repeat = pr_repeat_saved_2 #Restore the last parameter value\n",
    "            pr_miss = 1-pr_hit\n",
    "            pr_moveOn = 1-pr_repeat  \n",
    "            \n",
    "\n",
    "\n",
    "    if trace:\n",
    "        print('\\nBest parameter values found:')\n",
    "        print('\\nParameter values of the keyboard model:')\n",
    "        print('pr_hit =', pr_hit_saved_2)\n",
    "        print('pr_miss =', 1-pr_hit_saved_2)\n",
    "        print('deg_kb =', deg_kb)\n",
    "        print('\\nParameter values of the spelling model:')\n",
    "        print('pr_repeat =', pr_repeat_saved_2)\n",
    "        print('pr_moveOn =', 1-pr_repeat_saved_2)\n",
    "        print('deg_sp =', deg_sp)\n",
    "        \n",
    "        \n",
    "    pr_hit, pr_miss = pr_hit_saved, pr_miss_saved              # Restore values\n",
    "    pr_repeat, pr_moveOn = pr_repeat_saved, pr_moveOn_saved    # Restore values\n",
    "\n",
    "        \n",
    "    return (pr_hit_saved_2,1-pr_hit_saved_2, pr_repeat_saved_2,1-pr_repeat_saved_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pr_hit: 0.5662428160129971   pr_repeat: 0.4362023063839571\n",
      "Current logProbability =  -584.7005084670759\n",
      "************************************\n",
      "gradient ==>  3.2411837872696196 -3.3617362394822976\n",
      "0.5731836274810682 0.42900333866874313 ==> logProbability =  -580.0674007882335\n",
      "gradient ==>  3.1982192120428863 -3.311326513513677\n",
      "0.580130782570459 0.4218104924891039 ==> logProbability =  -575.4998759175197\n",
      "gradient ==>  3.1556470137431916 -3.261608993304094\n",
      "0.5870841447933971 0.4146236466025819 ==> logProbability =  -570.9971975589036\n",
      "gradient ==>  3.113436004717755 -3.212533988297423\n",
      "0.5940435885954121 0.40744268970488395 ==> logProbability =  -566.5586862743744\n",
      "gradient ==>  3.0715547573803406 -3.1640528363135445\n",
      "0.6010089989319871 0.40026752010109523 ==> logProbability =  -562.1837190278425\n",
      "gradient ==>  3.029971498438954 -3.116117703090822\n",
      "0.6079802708898254 0.3930980454139332 ==> logProbability =  -557.871728949186\n",
      "gradient ==>  2.9886539939792556 -3.0686813825477657\n",
      "0.6149573093497297 0.38593418232695165 ==> logProbability =  -553.622205325211\n",
      "gradient ==>  2.947569424262042 -3.02169709591476\n",
      "0.6219400286883009 0.37877585636072575 ==> logProbability =  -549.4346938265174\n",
      "gradient ==>  2.9066842469054563 -2.975118287811597\n",
      "0.6289283525158358 0.37162300168014484 ==> logProbability =  -545.308796981672\n",
      "gradient ==>  2.865964046898057 -2.928898417271057\n",
      "0.6359222134478876 0.3644755609309592 ==> logProbability =  -541.2441749127433\n",
      "gradient ==>  2.825373371628416 -2.8829907415631624\n",
      "0.6429215529079799 0.3573334851036948 ==> logProbability =  -537.2405463492184\n",
      "gradient ==>  2.78487554881724 -2.8373480905031556\n",
      "0.6499263209589052 0.3501967334229414 ==> logProbability =  -533.2976899406437\n",
      "gradient ==>  2.7444324848634096 -2.7919226286967387\n",
      "0.6569364761598643 0.34306527325980035 ==> logProbability =  -529.4154458921253\n",
      "gradient ==>  2.704004440695712 -2.7466656028910847\n",
      "0.6639519854464144 0.3359390800649502 ==> logProbability =  -525.5937179511573\n",
      "gradient ==>  2.6635497817012492 -2.7015270712429356\n",
      "0.6709728240297426 0.32881813731929843 ==> logProbability =  -521.8324757792551\n",
      "gradient ==>  2.6230246976912213 -2.6564556108813804\n",
      "0.6779989753111267 0.32170243649850055 ==> logProbability =  -518.1317577476764\n",
      "gradient ==>  2.5823828881198096 -2.611397999612336\n",
      "0.6850304308065347 0.3145919770466721 ==> logProbability =  -514.491674203311\n",
      "gradient ==>  2.5415752068889788 -2.5662988669624838\n",
      "0.6920671900750647 0.3074867663533318 ==> logProbability =  -510.9124112587931\n",
      "gradient ==>  2.5005492599889294 -2.521100308969608\n",
      "0.6991092606432507 0.30038681972587833 ==> logProbability =  -507.39423517030093\n",
      "gradient ==>  2.4592489479095434 -2.475741460173026\n",
      "0.7061566579149773 0.29329216034755284 ==> logProbability =  -503.9374973776921\n",
      "gradient ==>  2.4176139431669412 -2.4301580150738573\n",
      "0.7132094050537257 0.2862028192077235 ==> logProbability =  -500.5426402949264\n",
      "gradient ==>  2.3755790913123747 -2.384281689911461\n",
      "0.720267532819789 0.2791188349871082 ==> logProbability =  -497.2102039546983\n",
      "gradient ==>  2.3330737213858583 -2.338039613825458\n",
      "0.7273310793396498 0.2720402538749247 ==> logProbability =  -493.9408336303932\n",
      "gradient ==>  2.2900208487663463 -2.2913536363085996\n",
      "0.7344000897773486 0.2649671292873252 ==> logProbability =  -490.7352885817282\n",
      "gradient ==>  2.2463362496600325 -2.2441395351475535\n",
      "0.7414746158677601 0.25789952144618916 ==> logProbability =  -487.59445209868244\n",
      "gradient ==>  2.2019273817944622 -2.1963061056921447\n",
      "0.7485547152581986 0.2508374967633158 ==> logProbability =  -484.5193430528657\n",
      "gradient ==>  2.156692120039395 -2.1477541080732863\n",
      "0.7556404505863589 0.24378112695588208 ==> logProbability =  -481.51112920792275\n",
      "gradient ==>  2.110517268260651 -2.098375043674423\n",
      "0.7627318881972306 0.23673048779257827 ==> logProbability =  -478.5711425930719\n",
      "gradient ==>  2.063276799311609 -2.0480497253929\n",
      "0.769829096366473 0.22968565733312518 ==> logProbability =  -475.7008973091668\n",
      "gradient ==>  2.014829763021396 -1.9966465975762162\n",
      "0.7769321428485053 0.22264671347242498 ==> logProbability =  -472.9021102184446\n",
      "gradient ==>  1.9650177865688647 -1.9440197503309946\n",
      "0.7840410914980106 0.21561373052784902 ==> logProbability =  -470.1767250722017\n",
      "gradient ==>  1.913662071600129 -1.8900065583302421\n",
      "0.7911559976141193 0.2085867745041529 ==> logProbability =  -467.5269407615659\n",
      "gradient ==>  1.860559766385677 -1.8344248550477005\n",
      "0.7982769015126726 0.20156589652005666 ==> logProbability =  -464.955244544125\n",
      "gradient ==>  1.8054795571819113 -1.7770695277953905\n",
      "0.8054038196208829 0.1945511236599518 ==> logProbability =  -462.46445131551855\n",
      "gradient ==>  1.7481562780298532 -1.7177083844688923\n",
      "0.8125367320741884 0.18754244618602853 ==> logProbability =  -460.0577502769603\n",
      "gradient ==>  1.688284278769288 -1.656077095776368\n",
      "0.8196755653182075 0.1805397995496426 ==> logProbability =  -457.7387607205127\n",
      "gradient ==>  1.6255092120423456 -1.5918729512289929\n",
      "0.8268201674811598 0.17354303887536368 ==> logProbability =  -455.51159914726446\n",
      "gradient ==>  1.5594177948756283 -1.5247470745208602\n",
      "0.8339702731154953 0.16655190238564727 ==> logProbability =  -453.3809605977574\n",
      "gradient ==>  1.4895249604709875 -1.4542946100759764\n",
      "0.8411254520137103 0.1595659582880653 ==> logProbability =  -451.35221798049326\n",
      "gradient ==>  1.415257630818246 -1.3800421945254016\n",
      "0.8482850336353045 0.15258452641460768 ==> logProbability =  -449.4315444408544\n",
      "gradient ==>  1.3359341002642395 -1.3014317255468768\n",
      "0.8554479931917671 0.14560656035045394 ==> logProbability =  -447.62606558646735\n",
      "gradient ==>  1.2507377195221352 -1.217798966534076\n",
      "0.8626127755143607 0.13863046586500927 ==> logProbability =  -445.94405094475496\n",
      "gradient ==>  1.15868322725413 -1.1283447498799433\n",
      "0.8697770139645844 0.13165381284021752 ==> logProbability =  -444.39515782753637\n",
      "gradient ==>  1.0585737839787157 -1.0320952097642362\n",
      "0.8769370634687885 0.12467286082080452 ==> logProbability =  -442.99074663273\n",
      "gradient ==>  0.9489468312019653 -0.9278450488115482\n",
      "0.8840871831715597 0.11768173871945029 ==> logProbability =  -441.74429613966214\n",
      "gradient ==>  0.8280082998174407 -0.8140730795157083\n",
      "0.8912180015268482 0.11067093066446254 ==> logProbability =  -440.6719642035741\n",
      "gradient ==>  0.6935605274867953 -0.688808977511087\n",
      "0.8983133324541265 0.10362420950974048 ==> logProbability =  -439.7933733963993\n",
      "gradient ==>  0.5429502773043282 -0.5494047619895923\n",
      "0.9053424961820224 0.09651148448437699 ==> logProbability =  -439.1327879598613\n",
      "gradient ==>  0.37314341747674007 -0.39208867831064254\n",
      "0.9122363893484746 0.0892675741446817 ==> logProbability =  -438.7211711552564\n",
      "gradient ==>  0.18141316661257179 -0.21087270259062052\n",
      "0.9187580764655098 0.08168683558254292 ==> logProbability =  -438.60201752651017\n",
      "gradient ==>  -0.029722684581543035 0.0068626790805979\n",
      "0.9090144230025875 0.08393655049658924 ==> logProbability =  -438.837293436512\n",
      "\n",
      "Best parameter values found:\n",
      "\n",
      "Parameter values of the keyboard model:\n",
      "pr_hit = 0.9187580764655098\n",
      "pr_miss = 0.08124192353449022\n",
      "deg_kb = 2\n",
      "\n",
      "Parameter values of the spelling model:\n",
      "pr_repeat = 0.08168683558254292\n",
      "pr_moveOn = 0.9183131644174571\n",
      "deg_sp = 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9187580764655098,\n",
       " 0.08124192353449022,\n",
       " 0.08168683558254292,\n",
       " 0.9183131644174571)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learnBestParameterValuesGivenDocument1WhenTypingDocument2_GradientAscent('A.txt','biolaVision.txt', trace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pr_hit: 0.5488973360975442   pr_repeat: 0.4238192309605463\n",
      "Current logProbability =  -692.8534718005533\n",
      "************************************\n",
      "gradient ==>  1.6111652987889329 -3.1636692579103283\n",
      "0.5534354415875846 0.4149082490527392 ==> logProbability =  -689.3521093066731\n",
      "gradient ==>  1.5759832860815095 -3.101122296400945\n",
      "0.5579659471574033 0.405993400804909 ==> logProbability =  -685.9214856077118\n",
      "gradient ==>  1.5406987010429702 -3.0396047303526075\n",
      "0.5624870714797293 0.3970737912359832 ==> logProbability =  -682.5608164347047\n",
      "gradient ==>  1.5053116564967013 -2.97901986269153\n",
      "0.5669970413873094 0.3881485365375042 ==> logProbability =  -679.2694000790488\n",
      "gradient ==>  1.469821864389587 -2.919272712422412\n",
      "0.5714940907365536 0.3792167647563589 ==> logProbability =  -676.0466164736433\n",
      "gradient ==>  1.4342286771815225 -2.860269387392009\n",
      "0.5759764596450005 0.37027761664434133 ==> logProbability =  -672.8919268701522\n",
      "gradient ==>  1.3985311238150189 -2.8019164421607456\n",
      "0.580442394158637 0.3613302467000554 ==> logProbability =  -669.8048741386201\n",
      "gradient ==>  1.3627279397583152 -2.7441202104270133\n",
      "0.5848901464176283 0.35237382443206033 ==> logProbability =  -666.7850837274991\n",
      "gradient ==>  1.3268175904022428 -2.6867861002366453\n",
      "0.5893179754045283 0.34340753587643336 ==> logProbability =  -663.8322653355797\n",
      "gradient ==>  1.2907982868418912 -2.629817838586632\n",
      "0.59372414837839 0.33443058540734805 ==> logProbability =  -660.9462153628544\n",
      "gradient ==>  1.2546679927605737 -2.5731166499243727\n",
      "0.5981069431225281 0.32544219788617634 ==> logProbability =  -658.1268202256116\n",
      "gradient ==>  1.2184244207492156 -2.5165803502976587\n",
      "0.6024646511645809 0.3164416212035283 ==> logProbability =  -655.3740606427882\n",
      "gradient ==>  1.182065015909302 -2.460102335413694\n",
      "0.606795582167068 0.3074281292802115 ==> logProbability =  -652.6880170268256\n",
      "gradient ==>  1.1455869239756566 -2.403570436348332\n",
      "0.6110980697378553 0.29840102560831205 ==> logProbability =  -650.0688761441816\n",
      "gradient ==>  1.1089869404245292 -2.346865610869486\n",
      "0.6153704789769949 0.28935964743386794 ==> logProbability =  -647.5169392498922\n",
      "gradient ==>  1.0722614360190619 -2.289860430905719\n",
      "0.6196112161651486 0.280303370709904 ==> logProbability =  -645.0326319492699\n",
      "gradient ==>  1.0354062529470411 -2.232417317073441\n",
      "0.6238187411178504 0.2712316159859054 ==> logProbability =  -642.6165161007286\n",
      "gradient ==>  0.9984165639822322 -2.1743864587062944\n",
      "0.6279915828915695 0.2621438554514555 ==> logProbability =  -640.2693041505677\n",
      "gradient ==>  0.9612866848019621 -2.115603341532619\n",
      "0.6321283597503442 0.253039621424328 ==> logProbability =  -637.9918763882318\n",
      "gradient ==>  0.924009826487918 -2.055885783737267\n",
      "0.6362278046133755 0.24391851667682254 ==> logProbability =  -635.7853017357825\n",
      "gradient ==>  0.8865777709661415 -1.9950303527875803\n",
      "0.6402887976468654 0.23478022714420504 ==> logProbability =  -633.6508628470641\n",
      "gradient ==>  0.8489804461803487 -1.9328079976118033\n",
      "0.6443104083038232 0.22562453778054473 ==> logProbability =  -631.5900865026938\n",
      "gradient ==>  0.8112053693155303 -1.8689586799168865\n",
      "0.6482919500592454 0.21645135266032453 ==> logProbability =  -629.6047805634681\n",
      "gradient ==>  0.7732369141143636 -1.803184719640626\n",
      "0.6522330525075262 0.20726072093600026 ==> logProbability =  -627.6970791104559\n",
      "gradient ==>  0.7350553401411162 -1.7351424756575398\n",
      "0.6561337576729392 0.19805287106686578 ==> logProbability =  -625.8694978872128\n",
      "gradient ==>  0.6966354943098167 -1.6644318538207017\n",
      "0.6599946508304225 0.1888282570355635 ==> logProbability =  -624.1250028126245\n",
      "gradient ==>  0.6579450521368244 -1.590582956025628\n",
      "0.663817041728681 0.1795876224350119 ==> logProbability =  -622.4670952121744\n",
      "gradient ==>  0.6189420975749726 -1.5130389364444454\n",
      "0.6676032214871666 0.17033209204305522 ==> logProbability =  -620.8999186000246\n",
      "gradient ==>  0.5795717267195641 -1.4311337880603787\n",
      "0.6713568367534843 0.16106330720185483 ==> logProbability =  -619.428393429819\n",
      "gradient ==>  0.5397611655477021 -1.3440633122989993\n",
      "0.6750834523266491 0.15178363391181676 ==> logProbability =  -618.0583883085804\n",
      "gradient ==>  0.4994125415647659 -1.2508468996879856\n",
      "0.6787914299940229 0.14249649755994503 ==> logProbability =  -616.7969387344447\n",
      "gradient ==>  0.45839178756864385 -1.150276986734525\n",
      "0.6824933659430046 0.13320695127233567 ==> logProbability =  -615.6525270945174\n",
      "gradient ==>  0.41651082748592216 -1.040852351745798\n",
      "0.6862085790182705 0.1239227069947774 ==> logProbability =  -614.6354387268199\n",
      "gradient ==>  0.37349732370103084 -0.9206916248864445\n",
      "0.689967738835985 0.11465616948258434 ==> logProbability =  -613.758201930979\n",
      "gradient ==>  0.32893946640376726 -0.7874277590299243\n",
      "0.6938223238702642 0.1054289177675009 ==> logProbability =  -613.036081119842\n",
      "gradient ==>  0.28217518015605947 -0.6381053813239532\n",
      "0.6978666199447472 0.09628322647258383 ==> logProbability =  -612.4874235008468\n",
      "gradient ==>  0.2320387712217098 -0.46919648240134393\n",
      "0.7022995952961829 0.08731948118762824 ==> logProbability =  -612.1328602278161\n",
      "gradient ==>  0.1761596345104408 -0.2773223525971389\n",
      "0.7076614542646987 0.07887848193388186 ==> logProbability =  -611.9871984839592\n",
      "gradient ==>  0.10832934891436707 -0.06468778213798032\n",
      "0.7162471978852222 0.07375159140621881 ==> logProbability =  -611.9699460425414\n",
      "gradient ==>  0.0037338954547294634 0.08848990134003998\n",
      "0.7166687799831815 0.08374270088088079 ==> logProbability =  -611.8784701791897\n",
      "gradient ==>  0.008697587017195474 -0.1811887659578133\n",
      "0.7171482569211329 0.07375420240183136 ==> logProbability =  -611.9647362543874\n",
      "\n",
      "Best parameter values found:\n",
      "\n",
      "Parameter values of the keyboard model:\n",
      "pr_hit = 0.7166687799831815\n",
      "pr_miss = 0.28333122001681854\n",
      "deg_kb = 2\n",
      "\n",
      "Parameter values of the spelling model:\n",
      "pr_repeat = 0.08374270088088079\n",
      "pr_moveOn = 0.9162572991191192\n",
      "deg_sp = 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7166687799831815,\n",
       " 0.28333122001681854,\n",
       " 0.08374270088088079,\n",
       " 0.9162572991191192)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learnBestParameterValuesGivenDocument1WhenTypingDocument2_GradientAscent('B.txt','biolaVision.txt', trace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pr_hit: 0.5744018633263154   pr_repeat: 0.5793240321838802\n",
      "Current logProbability =  -782.5101310427731\n",
      "************************************\n",
      "gradient ==>  4.405131410691865 -3.6415812993400323\n",
      "0.5821092813567914 0.5729525561144365 ==> logProbability =  -776.8639084296008\n",
      "gradient ==>  4.335307839081111 -3.54760899702228\n",
      "0.5898483828070911 0.5666196019268579 ==> logProbability =  -771.3295961980971\n",
      "gradient ==>  4.265923863315493 -3.455724510173013\n",
      "0.5976187309911511 0.5603250257617397 ==> logProbability =  -765.9054991166827\n",
      "gradient ==>  4.196922508528587 -3.3657952849803223\n",
      "0.6054199263836526 0.554068720905995 ==> logProbability =  -760.5900531402681\n",
      "gradient ==>  4.128244176552357 -3.277697638439463\n",
      "0.6132516020151242 0.5478506137339197 ==> logProbability =  -755.3818215568103\n",
      "gradient ==>  4.059826362694594 -3.19131593570728\n",
      "0.6211134188901897 0.5416706594118447 ==> logProbability =  -750.2794919777537\n",
      "gradient ==>  3.9916033201595837 -3.106541846186701\n",
      "0.629005061366711 0.5355288372862238 ==> logProbability =  -745.2818741591025\n",
      "gradient ==>  3.9235056665468164 -3.023273667648141\n",
      "0.6369262324290221 0.5294251458620441 ==> logProbability =  -740.3878986532357\n",
      "gradient ==>  3.8554599254260893 -2.941415708792192\n",
      "0.644876648781932 0.523359597262339 ==> logProbability =  -735.5966163052406\n",
      "gradient ==>  3.787387994332448 -2.86087772151393\n",
      "0.6528560356832758 0.5173322110395504 ==> logProbability =  -730.9071986219292\n",
      "gradient ==>  3.7192065285438503 -2.7815743747815986\n",
      "0.6608641214209158 0.5113430071843952 ==> logProbability =  -726.3189390572124\n",
      "gradient ==>  3.650826227689322 -2.7034247624562795\n",
      "0.6689006313244786 0.5053919981464307 ==> logProbability =  -721.8312552746213\n",
      "gradient ==>  3.5821510094135647 -2.626351937604113\n",
      "0.6769652811816705 0.4994791796407691 ==> logProbability =  -717.4436924670292\n",
      "gradient ==>  3.5130770509457534 -2.5502824658326517\n",
      "0.6850577699023005 0.4936045199649686 ==> logProbability =  -713.1559278356774\n",
      "gradient ==>  3.443491675285486 -2.475145989928933\n",
      "0.6931777712381404 0.48776794748568264 ==> logProbability =  -708.9677763562029\n",
      "gradient ==>  3.3732720536659144 -2.400874797524466\n",
      "0.7013249243206834 0.48196933587171753 ==> logProbability =  -704.879197989453\n",
      "gradient ==>  3.30228368974997 -2.327403382620446\n",
      "0.7094988227178345 0.47620848654257775 ==> logProbability =  -700.8903065305537\n",
      "gradient ==>  3.2303786433521964 -2.254667990469443\n",
      "0.7176990016290756 0.47048510766086493 ==> logProbability =  -697.001380332381\n",
      "gradient ==>  3.15739344199676 -2.182606133423974\n",
      "0.725924922728801 0.4647987888111088 ==> logProbability =  -693.2128751909659\n",
      "gradient ==>  3.083146616862905 -2.111156062724376\n",
      "0.7341759560179287 0.45914897025988904 ==> logProbability =  -689.5254397425329\n",
      "gradient ==>  3.0074357850761544 -2.040256177566107\n",
      "0.7424513578378087 0.45353490535827573 ==> logProbability =  -685.9399337973884\n",
      "gradient ==>  2.9300341821822258 -1.9698443477838055\n",
      "0.75075024391293 0.447955614192531 ==> logProbability =  -682.4574501278264\n",
      "gradient ==>  2.850686526235677 -1.8998571195633076\n",
      "0.7590715558822548 0.4424098259609834 ==> logProbability =  -679.0793403392574\n",
      "gradient ==>  2.7691040673699945 -1.8302287639452288\n",
      "0.7674140191950987 0.43689590667667627 ==> logProbability =  -675.8072455900862\n",
      "gradient ==>  2.6849586432404067 -1.7608901142956483\n",
      "0.775776089395271 0.43141176754939387 ==> logProbability =  -672.6431330908928\n",
      "gradient ==>  2.5978755208908524 -1.6917671195607227\n",
      "0.7841558825509064 0.42595474760543495 ==> logProbability =  -669.5893395113293\n",
      "gradient ==>  2.507424760045751 -1.6227790121292855\n",
      "0.7925510836685438 0.42052146147322905 ==> logProbability =  -666.6486226559914\n",
      "gradient ==>  2.4131107845794304 -1.5538359479812698\n",
      "0.800958823958564 0.4151075993383413 ==> logProbability =  -663.8242230354484\n",
      "gradient ==>  2.314359806450625 -1.4848359152671264\n",
      "0.8093755131061029 0.40970766009852566 ==> logProbability =  -661.1199372407392\n",
      "gradient ==>  2.210504729701711 -1.4156606135373977\n",
      "0.8177966050245264 0.4043145894609889 ==> logProbability =  -658.5402052881975\n",
      "gradient ==>  2.10076721598125 -1.3461698593557685\n",
      "0.8262162626857547 0.3989192799362517 ==> logProbability =  -656.0902142407555\n",
      "gradient ==>  1.984236815087229 -1.276193840005476\n",
      "0.8346268652689159 0.3935098655328138 ==> logProbability =  -653.7760202207284\n",
      "gradient ==>  1.8598476669702677 -1.2055221532550604\n",
      "0.8430182605955131 0.3880707034215356 ==> logProbability =  -651.6046899524949\n",
      "gradient ==>  1.726354734154711 -1.1338879237775927\n",
      "0.8513765900933847 0.3825808648077867 ==> logProbability =  -649.5844602345145\n",
      "gradient ==>  1.5823148809580516 -1.0609441612489263\n",
      "0.8596823640630021 0.3770118326867063 ==> logProbability =  -647.7249071242579\n",
      "gradient ==>  1.4260858292641387 -0.9862275061456103\n",
      "0.8679071532637201 0.3713238767617933 ==> logProbability =  -646.0371014816635\n",
      "gradient ==>  1.255874010225284 -0.9091007797381963\n",
      "0.8760075708640427 0.36546015484645783 ==> logProbability =  -644.5336934934842\n",
      "gradient ==>  1.0699055749926174 -0.8286587242241694\n",
      "0.8839135747016968 0.3593368303148821 ==> logProbability =  -643.2287927133162\n",
      "gradient ==>  0.8669031570144625 -0.7435682053384198\n",
      "0.891503940959409 0.3528263510641829 ==> logProbability =  -642.1373428015157\n",
      "gradient ==>  0.6473347483180305 -0.6517926113026533\n",
      "0.8985507034191748 0.3457310611592082 ==> logProbability =  -641.2733559990083\n",
      "gradient ==>  0.4166610267902797 -0.550139110791406\n",
      "0.9045882580792305 0.3377593653718089 ==> logProbability =  -640.6460148238846\n",
      "gradient ==>  0.19361365508302697 -0.43376740308781336\n",
      "0.9086641958624796 0.32862773182752547 ==> logProbability =  -640.2545618081307\n",
      "gradient ==>  0.026879156383074587 -0.2974725548325523\n",
      "0.9095641139864022 0.3186683067753332 ==> logProbability =  -640.0912266694046\n",
      "gradient ==>  -0.012575794044892064 -0.1449145990238776\n",
      "0.9086995560719937 0.3087057498940585 ==> logProbability =  -640.1222254070598\n",
      "\n",
      "Best parameter values found:\n",
      "\n",
      "Parameter values of the keyboard model:\n",
      "pr_hit = 0.9095641139864022\n",
      "pr_miss = 0.09043588601359775\n",
      "deg_kb = 2\n",
      "\n",
      "Parameter values of the spelling model:\n",
      "pr_repeat = 0.3186683067753332\n",
      "pr_moveOn = 0.6813316932246668\n",
      "deg_sp = 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9095641139864022,\n",
       " 0.09043588601359775,\n",
       " 0.3186683067753332,\n",
       " 0.6813316932246668)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learnBestParameterValuesGivenDocument1WhenTypingDocument2_GradientAscent('C.txt','biolaVision.txt', trace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pr_hit: 0.7396152783832768   pr_repeat: 0.293162711168736\n",
      "Current logProbability =  -926.2744016326524\n",
      "************************************\n",
      "gradient ==>  -0.7159850959669711 1.205116219579054\n",
      "0.7345075315671314 0.3017598573500078 ==> logProbability =  -924.9396870068308\n",
      "gradient ==>  -0.6111278656021568 1.0448094563475934\n",
      "0.7294586190051717 0.3103916869325289 ==> logProbability =  -923.7936121180868\n",
      "gradient ==>  -0.5103698132310228 0.8895486501515961\n",
      "0.7244821221549677 0.3190654680630341 ==> logProbability =  -922.8296475344264\n",
      "gradient ==>  -0.4136914247844743 0.7387149317996773\n",
      "0.7195959889947029 0.32779047251805654 ==> logProbability =  -922.0417423220722\n",
      "gradient ==>  -0.32115466607456256 0.5917113904066582\n",
      "0.7148257597479186 0.33657938103579205 ==> logProbability =  -921.4242287448978\n",
      "gradient ==>  -0.23295366128775186 0.4479364424646519\n",
      "0.710211815943382 0.345451332487901 ==> logProbability =  -920.9716787007833\n",
      "gradient ==>  -0.14953070720116557 0.3067350930267594\n",
      "0.7058298562326341 0.3544401271286402 ==> logProbability =  -920.6785921552139\n",
      "gradient ==>  -0.07190881067560895 0.16727823864289348\n",
      "0.7018805443258611 0.363627234152237 ==> logProbability =  -920.5382240088288\n",
      "gradient ==>  -0.0031664576519006005 0.02809092952895753\n",
      "0.7007604209957451 0.3735643023177137 ==> logProbability =  -920.5200923186674\n",
      "gradient ==>  0.016901292269039914 -0.1188847348141735\n",
      "0.7021679223431957 0.3636638508150334 ==> logProbability =  -920.5355857173212\n",
      "\n",
      "Best parameter values found:\n",
      "\n",
      "Parameter values of the keyboard model:\n",
      "pr_hit = 0.7007604209957451\n",
      "pr_miss = 0.2992395790042549\n",
      "deg_kb = 2\n",
      "\n",
      "Parameter values of the spelling model:\n",
      "pr_repeat = 0.3735643023177137\n",
      "pr_moveOn = 0.6264356976822862\n",
      "deg_sp = 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7007604209957451,\n",
       " 0.2992395790042549,\n",
       " 0.3735643023177137,\n",
       " 0.6264356976822862)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learnBestParameterValuesGivenDocument1WhenTypingDocument2_GradientAscent('D.txt','biolaVision.txt', trace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pr_hit: 0.7845292852482257   pr_repeat: 0.37326376214722073\n",
      "Current logProbability =  -851.3687853736458\n",
      "************************************\n",
      "gradient ==>  -1.5684781024062886 -1.138965423804052\n",
      "0.7764376421076243 0.36738793784035456 ==> logProbability =  -849.658231598607\n",
      "gradient ==>  -1.3781117430562517 -1.069156870646566\n",
      "0.7685366024192928 0.3612582093110142 ==> logProbability =  -848.1300918676675\n",
      "gradient ==>  -1.2030960044526182 -0.9958812583927283\n",
      "0.7608333373016908 0.3548817128962159 ==> logProbability =  -846.7744796289267\n",
      "gradient ==>  -1.0417113877149404 -0.9190744944543212\n",
      "0.7533346637303104 0.3482658308938006 ==> logProbability =  -845.5832017672009\n",
      "gradient ==>  -0.8925127406752154 -0.8386507169162769\n",
      "0.7460471188476474 0.34141808019863273 ==> logProbability =  -844.5495484992489\n",
      "gradient ==>  -0.7542806837017224 -0.7544983928004285\n",
      "0.7389770714282797 0.33434599214149624 ==> logProbability =  -843.6681268547543\n",
      "gradient ==>  -0.62598394773579 -0.6664758890586882\n",
      "0.7321308946914481 0.32705696860688854 ==> logProbability =  -842.934730358412\n",
      "gradient ==>  -0.506750485285238 -0.5744061718619378\n",
      "0.7255152544775952 0.3195580817187662 ==> logProbability =  -842.3462394210187\n",
      "gradient ==>  -0.395846305018722 -0.4780699760353855\n",
      "0.7191376441875625 0.3118557387642835 ==> logProbability =  -841.9005483737556\n",
      "gradient ==>  -0.2926625627626436 -0.3771960100036722\n",
      "0.7130075360525714 0.30395499359352174 ==> logProbability =  -841.5965160291399\n",
      "gradient ==>  -0.19671521785664936 -0.27144443849851996\n",
      "0.7071394637864686 0.29585772690161916 ==> logProbability =  -841.4339362752911\n",
      "gradient ==>  -0.10767552955314841 -0.1603708414504581\n",
      "0.7015651945372801 0.28755546682754596 ==> logProbability =  -841.4135146969987\n",
      "gradient ==>  -0.025535097293072795 -0.043302948524683416\n",
      "0.6964857190758698 0.27894158680534165 ==> logProbability =  -841.5365267721779\n",
      "\n",
      "Best parameter values found:\n",
      "\n",
      "Parameter values of the keyboard model:\n",
      "pr_hit = 0.7015651945372801\n",
      "pr_miss = 0.29843480546271994\n",
      "deg_kb = 2\n",
      "\n",
      "Parameter values of the spelling model:\n",
      "pr_repeat = 0.28755546682754596\n",
      "pr_moveOn = 0.712444533172454\n",
      "deg_sp = 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7015651945372801,\n",
       " 0.29843480546271994,\n",
       " 0.28755546682754596,\n",
       " 0.712444533172454)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learnBestParameterValuesGivenDocument1WhenTypingDocument2_GradientAscent('E.txt','biolaVision.txt', trace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pr_hit: 0.2644594542225491   pr_repeat: 0.3849404960068553\n",
      "Current logProbability =  -943.5955555942177\n",
      "************************************\n",
      "gradient ==>  9.72943092015987 -0.9595558174993357\n",
      "0.27441117264412956 0.38395901729716464 ==> logProbability =  -933.8235757863026\n",
      "gradient ==>  9.409517206944884 -0.9568647214877046\n",
      "0.2843598647772079 0.3829473232518996 ==> logProbability =  -924.3704589651072\n",
      "gradient ==>  9.108923964990709 -0.9531853188055948\n",
      "0.294305559551822 0.38190657570796144 ==> logProbability =  -915.2169945866322\n",
      "gradient ==>  8.825866503902262 -0.9485809612203866\n",
      "0.3042482982323732 0.3808379562573284 ==> logProbability =  -906.3457577661337\n",
      "gradient ==>  8.558770777683208 -0.9431087673461889\n",
      "0.3141881341050862 0.37974266505243004 ==> logProbability =  -897.7408982224367\n",
      "gradient ==>  8.306242916335577 -0.9368206002168336\n",
      "0.32412513211780297 0.37862191954373337 ==> logProbability =  -889.3879597011953\n",
      "gradient ==>  8.0670438677314 -0.9297638741345509\n",
      "0.33405936847345297 0.3774769531555445 ==> logProbability =  -881.273724766517\n",
      "gradient ==>  7.840068179562081 -0.9219822243833278\n",
      "0.34399093017881327 0.3763090139051463 ==> logProbability =  -873.3860808209054\n",
      "gradient ==>  7.624326154962887 -0.9135160657406232\n",
      "0.35391991455046695 0.3751193629700156 ==> logProbability =  -865.7139039801356\n",
      "gradient ==>  7.418928772201866 -0.9044030601072564\n",
      "0.363846428680159 0.3739092732076324 ==> logProbability =  -858.246958039505\n",
      "gradient ==>  7.223074880512854 -0.8946785093412473\n",
      "0.3737705888620208 0.37268002763218827 ==> logProbability =  -850.9758062559654\n",
      "gradient ==>  7.036040279285771 -0.8843756861730299\n",
      "0.3836925199843743 0.3714329178522278 ==> logProbability =  -843.8917340635389\n",
      "gradient ==>  6.857168362689208 -0.8735261136050667\n",
      "0.3936123548890322 0.37016924247289507 ==> logProbability =  -836.9866811574041\n",
      "gradient ==>  6.685862071059205 -0.862159801256098\n",
      "0.4035302337011793 0.3688903054660166 ==> logProbability =  -830.2531816407368\n",
      "gradient ==>  6.521576937541113 -0.8503054455683241\n",
      "0.41344630313305675 0.36759741451075967 ==> logProbability =  -823.6843111399096\n",
      "gradient ==>  6.363815056165095 -0.8379905995682293\n",
      "0.42336071576477213 0.3662918793070662 ==> logProbability =  -817.2736399674566\n",
      "gradient ==>  6.212119827837682 -0.8252418168696067\n",
      "0.43327362930563645 0.36497500986351883 ==> logProbability =  -811.0151915556978\n",
      "gradient ==>  6.066071365145945 -0.8120847738030079\n",
      "0.44318520583947923 0.3636481147607403 ==> logProbability =  -804.9034055029824\n",
      "gradient ==>  5.9252824566742675 -0.7985443728821338\n",
      "0.45309561105742313 0.36231249939090143 ==> logProbability =  -798.9331046737585\n",
      "gradient ==>  5.789395007605776 -0.7846448302767612\n",
      "0.4630050134816128 0.36096946417339465 ==> logProbability =  -793.0994658768518\n",
      "gradient ==>  5.658076886488971 -0.7704097495088718\n",
      "0.4729135836833862 0.3596203027462377 ==> logProbability =  -787.3979937163936\n",
      "gradient ==>  5.531019118775248 -0.7558621832059771\n",
      "0.48282149349936027 0.3582663001323092 ==> logProbability =  -781.8244972691717\n",
      "gradient ==>  5.4079333764898365 -0.7410246844460744\n",
      "0.4927289152488672 0.35690873087904895 ==> logProbability =  -776.3750692927493\n",
      "gradient ==>  5.288549720589003 -0.7259193489536528\n",
      "0.502636020956132 0.3555488571698099 ==> logProbability =  -771.0460677120735\n",
      "gradient ==>  5.1726145584262895 -0.7105678491985827\n",
      "0.5125429815805195 0.35418792690457324 ==> logProbability =  -765.8340991698078\n",
      "gradient ==>  5.059888783538327 -0.6949914612591783\n",
      "0.5224499662580985 0.35282717174723793 ==> logProbability =  -760.7360044583352\n",
      "gradient ==>  4.950146068829213 -0.6792110851611142\n",
      "0.5323571415576773 0.35146780513612297 ==> logProbability =  -755.7488456802278\n",
      "gradient ==>  4.843171287329369 -0.663247259263926\n",
      "0.5422646707543416 0.35011102025367286 ==> logProbability =  -750.8698950097286\n",
      "gradient ==>  4.738759037100408 -0.6471201691646229\n",
      "0.5521727131233815 0.3487579879505434 ==> logProbability =  -746.0966249511382\n",
      "gradient ==>  4.636712248676986 -0.6308496514780018\n",
      "0.5620814232573201 0.3474098546182722 ==> logProbability =  -741.4267000115333\n",
      "gradient ==>  4.536840854664774 -0.6144551927750399\n",
      "0.5719909504085404 0.3460677400034842 ==> logProbability =  -736.8579697255387\n",
      "gradient ==>  4.438960501833776 -0.5979559238768388\n",
      "0.5819014378597474 0.3447327349550031 ==> logProbability =  -732.3884629894603\n",
      "gradient ==>  4.342891286233112 -0.5813706096303122\n",
      "0.5918130223241923 0.34340589909319763 ==> logProbability =  -728.0163836814706\n",
      "gradient ==>  4.248456491489833 -0.5647176342147304\n",
      "0.6017258333772052 0.3420882583882761 ==> logProbability =  -723.7401075643027\n",
      "gradient ==>  4.15548130950674 -0.5480149819640019\n",
      "0.6116399929201168 0.34078080263082455 ==> logProbability =  -719.5581804876078\n",
      "gradient ==>  4.063791521175631 -0.5312802135948687\n",
      "0.6215556146770959 0.3394844827734885 ==> logProbability =  -715.4693179294486\n",
      "gradient ==>  3.9732121123360002 -0.5145304376558215\n",
      "0.6314728037247307 0.33820020811693235 ==> logProbability =  -711.4724059410937\n",
      "gradient ==>  3.883565796927769 -0.4977822768955775\n",
      "0.6413916560533399 0.33692884330569833 ==> logProbability =  -707.5665035872828\n",
      "gradient ==>  3.7946714148690717 -0.4810518291203607\n",
      "0.6513122581579367 0.3356712050897275 ==> logProbability =  -703.75084700655\n",
      "gradient ==>  3.70634216636131 -0.4643546219519976\n",
      "0.6612346866554414 0.33442805879427145 ==> logProbability =  -700.0248552544731\n",
      "gradient ==>  3.6183836367229105 -0.4477055606787417\n",
      "0.6711590079230473 0.3332001144236481 ==> logProbability =  -696.3881381386209\n",
      "gradient ==>  3.530591555934052 -0.4311188681213025\n",
      "0.6810852777504602 0.33198802230116276 ==> logProbability =  -692.8405063098298\n",
      "gradient ==>  3.442749224154568 -0.4146080150705984\n",
      "0.6910135409958738 0.3307923681163041 ==> logProbability =  -689.3819839432786\n",
      "gradient ==>  3.3546245176073626 -0.3981856393587577\n",
      "0.7009438312317279 0.32961366720780366 ==> logProbability =  -686.0128244286087\n",
      "gradient ==>  3.2659663670574446 -0.3818634509581216\n",
      "0.7108761703611263 0.32845235785254057 ==> logProbability =  -682.7335295963826\n",
      "gradient ==>  3.1765005718514203 -0.36565211957963584\n",
      "0.720810568178627 0.32730879324848977 ==> logProbability =  -679.5448731456203\n",
      "gradient ==>  3.0859247735769486 -0.3495611399542895\n",
      "0.7307470218390145 0.32618323176417596 ==> logProbability =  -676.4479291137322\n",
      "gradient ==>  2.9939023611871107 -0.33359866815430905\n",
      "0.7406855151830876 0.32507582486072284 ==> logProbability =  -673.4441064592489\n",
      "gradient ==>  2.9000550088181853 -0.3177713196902232\n",
      "0.7506260178480046 0.32398660184922484 ==> logProbability =  -670.535191127924\n",
      "gradient ==>  2.803953450962581 -0.30208391627138553\n",
      "0.7605684840572873 0.32291545028325824 ==> logProbability =  -667.7233973702237\n",
      "gradient ==>  2.7051059662678654 -0.2865391623893174\n",
      "0.7705128509353336 0.3218620902333158 ==> logProbability =  -665.0114306101746\n",
      "gradient ==>  2.6029438547220707 -0.27113722414776475\n",
      "0.7804590361113014 0.32082603982655067 ==> logProbability =  -662.4025648858113\n",
      "gradient ==>  2.496802928950842 -0.25587516911093644\n",
      "0.7904069342459308 0.3198065680500712 ==> logProbability =  -659.9007388687983\n",
      "gradient ==>  2.3858996613840873 -0.24074620406599934\n",
      "0.8003564118919005 0.3188026285238309 ==> logProbability =  -657.5106758423353\n",
      "gradient ==>  2.2693000771564584 -0.22573861136720552\n",
      "0.8103072997046777 0.3178127640192027 ==> logProbability =  -655.2380349492914\n",
      "gradient ==>  2.145878666083263 -0.21083422244225858\n",
      "0.8202593802941535 0.3168349644791222 ==> logProbability =  -653.0896037895261\n",
      "gradient ==>  2.0142633586978036 -0.1960061561337625\n",
      "0.8302123685939821 0.31586644813776604 ==> logProbability =  -651.0735464756507\n",
      "gradient ==>  1.8727607306088885 -0.18121534170256837\n",
      "0.8401658787001509 0.31490330922442344 ==> logProbability =  -649.1997272407813\n",
      "gradient ==>  1.7192526679428966 -0.1664049338623954\n",
      "0.8501193646007603 0.31393992019273853 ==> logProbability =  -647.4801387730189\n",
      "gradient ==>  1.551051080201546 -0.1514908499826788\n",
      "0.8600720062103934 0.3129678476696206 ==> logProbability =  -645.9294785870788\n",
      "gradient ==>  1.3646897961984905 -0.1363446263055721\n",
      "0.8700224678449008 0.31197370821250436 ==> logProbability =  -644.565939457403\n",
      "gradient ==>  1.1556209000717672 -0.12075952935231271\n",
      "0.879968312298017 0.3109343920361571 ==> logProbability =  -643.4123181480697\n",
      "gradient ==>  0.9177651415110404 -0.10437509766893527\n",
      "0.8899042632623415 0.3098044015784375 ==> logProbability =  -642.4976168333162\n",
      "gradient ==>  0.6428505449024442 -0.08647713734171703\n",
      "0.8998149930294728 0.30847119661186334 ==> logProbability =  -641.8594758197596\n",
      "gradient ==>  0.3195663525193595 -0.06529221943321772\n",
      "0.9096125852877432 0.30646940093280967 ==> logProbability =  -641.5486537659536\n",
      "gradient ==>  -0.06529286707598203 -0.03346763184538304\n",
      "0.9007135314745581 0.30190794927461634 ==> logProbability =  -641.8595466155026\n",
      "\n",
      "Best parameter values found:\n",
      "\n",
      "Parameter values of the keyboard model:\n",
      "pr_hit = 0.9096125852877432\n",
      "pr_miss = 0.09038741471225675\n",
      "deg_kb = 2\n",
      "\n",
      "Parameter values of the spelling model:\n",
      "pr_repeat = 0.30646940093280967\n",
      "pr_moveOn = 0.6935305990671903\n",
      "deg_sp = 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9096125852877432,\n",
       " 0.09038741471225675,\n",
       " 0.30646940093280967,\n",
       " 0.6935305990671903)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learnBestParameterValuesGivenDocument1WhenTypingDocument2_GradientAscent('F.txt','biolaVision.txt', trace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pr_hit: 0.38951118514769234   pr_repeat: 0.36864345820513467\n",
      "Current logProbability =  -708.3829689500178\n",
      "************************************\n",
      "gradient ==>  3.390093004799951 -2.5517269702602334\n",
      "0.3975008141791445 0.36262965508732503 ==> logProbability =  -704.1631753610834\n",
      "gradient ==>  3.2993026675775354 -2.5112297828113697\n",
      "0.4054580656976643 0.35657307616263373 ==> logProbability =  -700.0406924767359\n",
      "gradient ==>  3.2111230674053104 -2.4703717057828953\n",
      "0.41338397511362085 0.35047553896061096 ==> logProbability =  -696.0135488518023\n",
      "gradient ==>  3.125360090704362 -2.429140908516956\n",
      "0.4212795716518142 0.3443388007955863 ==> logProbability =  -692.0799578943142\n",
      "gradient ==>  3.041833191106207 -2.387521943782531\n",
      "0.42914588205706133 0.338164567190652 ==> logProbability =  -688.2383070368232\n",
      "gradient ==>  2.960373908112615 -2.3454957321815755\n",
      "0.43698393485839715 0.3319545005015196 ==> logProbability =  -684.4871484247958\n",
      "gradient ==>  2.880824538863635 -2.3030395143733813\n",
      "0.44479476525006567 0.3257102288392208 ==> logProbability =  -680.8251909814142\n",
      "gradient ==>  2.803036940846482 -2.2601267706145336\n",
      "0.4525794206645191 0.31943335540746987 ==> logProbability =  -677.2512937314625\n",
      "gradient ==>  2.72687144627605 -2.216727106838789\n",
      "0.4603389671323056 0.3131254683908642 ==> logProbability =  -673.7644602872865\n",
      "gradient ==>  2.652195871237609 -2.1728061062349298\n",
      "0.468074496546781 0.306788151555027 ==> logProbability =  -670.3638344175799\n",
      "gradient ==>  2.578884604547852 -2.1283251450424814\n",
      "0.4757871349789079 0.300422995750549 ==> logProbability =  -667.0486966354076\n",
      "gradient ==>  2.506817762781793 -2.083241171073041\n",
      "0.4834780522202161 0.2940316115509137 ==> logProbability =  -663.8184617557056\n",
      "gradient ==>  2.435880399027269 -2.0375064433283114\n",
      "0.49114847277173296 0.28761564330263906 ==> logProbability =  -660.6726773847347\n",
      "gradient ==>  2.365961753707438 -1.9910682310392076\n",
      "0.4987996885452175 0.2811767849265307 ==> logProbability =  -657.6110233147167\n",
      "gradient ==>  2.296954536287103 -1.9438684705725109\n",
      "0.5064330736027409 0.27471679788601905 ==> logProbability =  -654.6333118061596\n",
      "gradient ==>  2.2287542268250036 -1.8958433789923674\n",
      "0.5140501013346233 0.2682375318371725 ==> logProbability =  -651.7394887480414\n",
      "gradient ==>  2.1612583861486883 -1.8469230237795955\n",
      "0.5216523645679072 0.2617409486019743 ==> logProbability =  -648.9296356917703\n",
      "gradient ==>  2.0943659628810565 -1.7970308494432174\n",
      "0.5292415992130928 0.25522915027122756 ==> logProbability =  -646.2039727581218\n",
      "gradient ==>  2.0279765845755264 -1.7460831637752108\n",
      "0.5368197122024828 0.24870441245886776 ==> logProbability =  -643.5628624162762\n",
      "gradient ==>  1.9619898187526132 -1.6939885896717897\n",
      "0.5443888146579876 0.24216922401337737 ==> logProbability =  -641.0068141292763\n",
      "gradient ==>  1.8963043875498897 -1.6406474933310164\n",
      "0.5519512614610896 0.23562633486940962 ==> logProbability =  -638.5364898486371\n",
      "gradient ==>  1.8308173168652502 -1.5859514070241403\n",
      "0.5595096986980235 0.229078814229096 ==> logProbability =  -636.1527103193541\n",
      "gradient ==>  1.765422997054202 -1.5297824757822127\n",
      "0.5670671208387352 0.22253012194841285 ==> logProbability =  -633.8564621206485\n",
      "gradient ==>  1.700012127193645 -1.4720129739987442\n",
      "0.5746269400046133 0.21598419694279122 ==> logProbability =  -631.6489053106108\n",
      "gradient ==>  1.634470508212189 -1.412504962885123\n",
      "0.5821930703201965 0.2094455677250107 ==> logProbability =  -629.5313814544853\n",
      "gradient ==>  1.5686776413671168 -1.3511101970091204\n",
      "0.5897700311695602 0.20291949200623377 ==> logProbability =  -627.5054216817102\n",
      "gradient ==>  1.5025050768861092 -1.2876704441014226\n",
      "0.5973630742384862 0.19641213486577846 ==> logProbability =  -625.5727542139127\n",
      "gradient ==>  1.4358144422864143 -1.222018466497957\n",
      "0.604978340573636 0.18993079868835835 ==> logProbability =  -623.7353105019118\n",
      "gradient ==>  1.3684550597854468 -1.1539800398994657\n",
      "0.6126230555774611 0.18348422343398554 ==> logProbability =  -621.9952286555521\n",
      "gradient ==>  1.3002610361282905 -1.083377578624436\n",
      "0.6203057718922237 0.17708298370820735 ==> logProbability =  -620.3548521735942\n",
      "gradient ==>  1.231047674800493 -1.010036232306902\n",
      "0.6280366724039755 0.17074002089281937 ==> logProbability =  -618.8167209760461\n",
      "gradient ==>  1.1606070194371796 -0.9337937736224831\n",
      "0.6358279477240212 0.1644713664209851 ==> logProbability =  -617.383550256314\n",
      "gradient ==>  1.088702289937146 -0.8545162987741151\n",
      "0.6436942633986674 0.15829713952955857 ==> logProbability =  -616.0581904963043\n",
      "gradient ==>  1.01506092728971 -0.7721228499987092\n",
      "0.6516533290848475 0.15224294483471507 ==> logProbability =  -614.8435588612069\n",
      "gradient ==>  0.9393659431161723 -0.6866237520655432\n",
      "0.6597265687185223 0.14634186003467511 ==> logProbability =  -613.742527852657\n",
      "gradient ==>  0.8612453372978734 -0.5981800364448873\n",
      "0.6679398528521177 0.14063730363291774 ==> logProbability =  -612.7577515140704\n",
      "gradient ==>  0.7802596547255689 -0.5071951967221366\n",
      "0.676324159282635 0.13518722054371762 ==> logProbability =  -611.8914035108497\n",
      "gradient ==>  0.6958886660150938 -0.4144560094538292\n",
      "0.6849158041638417 0.13007022550412303 ==> logProbability =  -611.1447986397596\n",
      "gradient ==>  0.6075205297663615 -0.3213459493405253\n",
      "0.6937553828689035 0.1253945599560949 ==> logProbability =  -610.5178806240765\n",
      "gradient ==>  0.5144525345044713 -0.23015994881916413\n",
      "0.7028834983809733 0.12131074957872538 ==> logProbability =  -610.0086122906838\n",
      "gradient ==>  0.41592555235240525 -0.14454228878105368\n",
      "0.7123293642349615 0.11802812589202906 ==> logProbability =  -609.6124578158485\n",
      "gradient ==>  0.31124124598545677 -0.07002172241050175\n",
      "0.7220855125296856 0.11583322943630424 ==> logProbability =  -609.3224729392346\n",
      "gradient ==>  0.2000578511739377 -0.014484661323649561\n",
      "0.7320594046187915 0.11511109607267174 ==> logProbability =  -609.1308857161387\n",
      "gradient ==>  0.08303292065807 0.011670079483224072\n",
      "0.7419620760439021 0.11650289298540698 ==> logProbability =  -609.0319128517946\n",
      "gradient ==>  -0.03640032340160815 -0.006709197173790926\n",
      "0.7321277307068415 0.11469025628947652 ==> logProbability =  -609.1351854752155\n",
      "\n",
      "Best parameter values found:\n",
      "\n",
      "Parameter values of the keyboard model:\n",
      "pr_hit = 0.7419620760439021\n",
      "pr_miss = 0.2580379239560979\n",
      "deg_kb = 2\n",
      "\n",
      "Parameter values of the spelling model:\n",
      "pr_repeat = 0.11650289298540698\n",
      "pr_moveOn = 0.883497107014593\n",
      "deg_sp = 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7419620760439021,\n",
       " 0.2580379239560979,\n",
       " 0.11650289298540698,\n",
       " 0.883497107014593)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learnBestParameterValuesGivenDocument1WhenTypingDocument2_GradientAscent('G.txt','biolaVision.txt', trace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pr_hit: 0.261845923298849   pr_repeat: 0.7483446806248677\n",
      "Current logProbability =  -852.9828378525763\n",
      "************************************\n",
      "gradient ==>  6.0281444968818505 -7.069004033343504\n",
      "0.26833457923110077 0.7407356501877586 ==> logProbability =  -843.8405019371464\n",
      "gradient ==>  5.922439230004329 -6.877425872558774\n",
      "0.27485994432727245 0.7331580773334955 ==> logProbability =  -834.9035282105049\n",
      "gradient ==>  5.819336935149522 -6.696596368353994\n",
      "0.2814192983384289 0.725609907028294 ==> logProbability =  -826.1627268737423\n",
      "gradient ==>  5.718806371948858 -6.525542995687829\n",
      "0.28801018853321075 0.7180892576919449 ==> logProbability =  -817.6096086958592\n",
      "gradient ==>  5.620804646727947 -6.363410089503532\n",
      "0.29463039789184753 0.7105944042545641 ==> logProbability =  -809.2363094055409\n",
      "gradient ==>  5.52528021768785 -6.209441615052015\n",
      "0.30127791770653317 0.7031237630295177 ==> logProbability =  -801.0355247161212\n",
      "gradient ==>  5.432175251678359 -6.062966882080673\n",
      "0.30795092390547746 0.6956758782110709 ==> logProbability =  -793.0004541957821\n",
      "gradient ==>  5.34142746554096 -5.923388630214504\n",
      "0.3146477565320743 0.6882494098194767 ==> logProbability =  -785.124752547976\n",
      "gradient ==>  5.252971559495904 -5.790173038841317\n",
      "0.3213669019048353 0.6808431229319936 ==> logProbability =  -777.4024871387228\n",
      "gradient ==>  5.166740329045524 -5.662841309924261\n",
      "0.32810697706157566 0.6734558780544028 ==> logProbability =  -769.8281008188932\n",
      "gradient ==>  5.082665524569279 -5.540962544624222\n",
      "0.33486671615570135 0.6660866225031717 ==> logProbability =  -762.3963792561608\n",
      "gradient ==>  5.000678513620642 -5.424147690279369\n",
      "0.34164495852574156 0.6587343826830223 ==> logProbability =  -755.1024221240307\n",
      "gradient ==>  4.9207107893749935 -5.312044377451912\n",
      "0.3484406382034448 0.6513982571580568 ==> logProbability =  -747.9416176022899\n",
      "gradient ==>  4.842694359339362 -5.204332500530427\n",
      "0.35525277466243343 0.6440774104266931 ==> logProbability =  -740.9096197302852\n",
      "gradient ==>  4.766562040934673 -5.100720422045697\n",
      "0.3620804646399061 0.636771067321451 ==> logProbability =  -734.0023282259481\n",
      "gradient ==>  4.692247684599806 -5.000941702097862\n",
      "0.36892287488927866 0.6294785079641826 ==> logProbability =  -727.2158704426905\n",
      "gradient ==>  4.6196863403682755 -4.904752271365055\n",
      "0.3757792357428488 0.6221990632157398 ==> logProbability =  -720.5465851856418\n",
      "gradient ==>  4.548814380196859 -4.811927979949473\n",
      "0.3826488353813111 0.6149321105664349 ==> logProbability =  -713.991008150023\n",
      "gradient ==>  4.479569585466379 -4.722262465580684\n",
      "0.3895310147218003 0.6076770704200716 ==> logProbability =  -707.5458587792339\n",
      "gradient ==>  4.41189120689296 -4.635565293889385\n",
      "0.3964251628486487 0.6004334027299388 ==> logProbability =  -701.208028369573\n",
      "gradient ==>  4.345720002392568 -4.551660331065136\n",
      "0.403330712921564 0.5932006039500433 ==> logProbability =  -694.9745692733569\n",
      "gradient ==>  4.280998257166857 -4.4703843154705964\n",
      "0.41024713850484 0.5859782042691196 ==> logProbability =  -688.8426850732667\n",
      "gradient ==>  4.217669789301226 -4.391585600006238\n",
      "0.4171739502687517 0.578765765098677 ==> logProbability =  -682.8097216186594\n",
      "gradient ==>  4.155679943430641 -4.315123041341735\n",
      "0.42411069302071003 0.5715628767895921 ==> logProbability =  -676.8731588298078\n",
      "gradient ==>  4.094975574457749 -4.2408650157618695\n",
      "0.43105694302921177 0.5643691565545962 ==> logProbability =  -671.030603189027\n",
      "gradient ==>  4.035505022897041 -4.168688544399629\n",
      "0.43801230560831234 0.5571842465765069 ==> logProbability =  -665.2797808487253\n",
      "gradient ==>  3.9772180830773323 -4.098478513175451\n",
      "0.444976412934358 0.5500078122842336 ==> logProbability =  -659.6185312959005\n",
      "gradient ==>  3.920065965197864 -4.030126974896575\n",
      "0.45194892207017956 0.5428395407805247 ==> logProbability =  -654.0448015207221\n",
      "gradient ==>  3.8640012520274922 -3.963532522773221\n",
      "0.4589295131749302 0.5356791394071185 ==> logProbability =  -648.5566406438088\n",
      "gradient ==>  3.8089778508897325 -3.8985997261280545\n",
      "0.4659178878803364 0.5285263344344635 ==> logProbability =  -643.1521949628143\n",
      "gradient ==>  3.754950941452762 -3.835238620351788\n",
      "0.4729137678163808 0.5213808698645107 ==> logProbability =  -637.8297033841015\n",
      "gradient ==>  3.7018769197354686 -3.7733642442562996\n",
      "0.4799168932713798 0.5142425063362541 ==> logProbability =  -632.5874932097747\n",
      "gradient ==>  3.649713338663446 -3.712896218883543\n",
      "0.48692702197313165 0.5071110201247498 ==> logProbability =  -627.4239762542257\n",
      "gradient ==>  3.5984188454311834 -3.6537583626144396\n",
      "0.4939439279792998 0.49998620222528034 ==> logProbability =  -622.3376452677511\n",
      "gradient ==>  3.547953115853602 -3.5958783380883688\n",
      "0.5009674006664925 0.4928678575151487 ==> logProbability =  -617.3270706477849\n",
      "gradient ==>  3.4982767858464285 -3.5391873269911684\n",
      "0.5079972438086606 0.48575580398634904 ==> logProbability =  -612.3908974209235\n",
      "gradient ==>  3.449351380093958 -3.4836197292615907\n",
      "0.5150332747364248 0.47864987204299736 ==> logProbability =  -607.5278424812661\n",
      "gradient ==>  3.401139237926145 -3.429112883658945\n",
      "0.522075323569834 0.4715499038580067 ==> logProbability =  -602.7366920727102\n",
      "gradient ==>  3.353603436357389 -3.37560680697743\n",
      "0.5291232325178297 0.4644557527840048 ==> logProbability =  -598.0162995047501\n",
      "gradient ==>  3.3067077101908353 -3.3230439494798247\n",
      "0.5361768552383716 0.457367282813958 ==> logProbability =  -593.3655830930904\n",
      "gradient ==>  3.2604163690220958 -3.2713689643637736\n",
      "0.543236056253769 0.4502843680873634 ==> logProbability =  -588.7835243180276\n",
      "gradient ==>  3.2146942109229713 -3.22052848927126\n",
      "0.5503007104162817 0.44320689243822886 ==> logProbability =  -584.2691661951056\n",
      "gradient ==>  3.1695064325107296 -3.170470938013409\n",
      "0.5573707024194954 0.4361347489813627 ==> logProbability =  -579.8216118540453\n",
      "gradient ==>  3.1248185350369795 -3.121146300812029\n",
      "0.5644459263513605 0.4290678397337522 ==> logProbability =  -575.4400233234094\n",
      "gradient ==>  3.0805962260490105 -3.0725059514652457\n",
      "0.5715262852850908 0.4220060752680152 ==> logProbability =  -571.1236205199237\n",
      "gradient ==>  3.03680531608768 -3.0245024599068984\n",
      "0.5786116909043808 0.4149493743950765 ==> logProbability =  -566.8716804428504\n",
      "gradient ==>  2.9934116097822425 -2.9770894086886983\n",
      "0.5857020631595877 0.40789766387332427 ==> logProbability =  -562.6835365753398\n",
      "gradient ==>  2.9503807905923622 -2.9302212119257547\n",
      "0.5927973299516597 0.4008508781415654 ==> logProbability =  -558.5585784962802\n",
      "gradient ==>  2.907678298320434 -2.8838529352524347\n",
      "0.5998974268406572 0.39380895907309776 ==> logProbability =  -554.4962517078798\n",
      "gradient ==>  2.865269198365013 -2.837940115304491\n",
      "0.6070022967757058 0.3867718557481464 ==> logProbability =  -550.4960576860424\n",
      "gradient ==>  2.8231180415241397 -2.7924385771906373\n",
      "0.614111889843137 0.37973952424177276 ==> logProbability =  -546.557554162625\n",
      "gradient ==>  2.7811887129606703 -2.747304248342175\n",
      "0.6212261630293919 0.37271192742413056 ==> logProbability =  -542.6803556508758\n",
      "gradient ==>  2.739444268712532 -2.702492967010812\n",
      "0.6283450799949803 0.36568903476960013 ==> logProbability =  -538.8641342278429\n",
      "gradient ==>  2.6978467578769596 -2.6579602835519154\n",
      "0.6354686108553742 0.35867082217086704 ==> logProbability =  -535.1086205903333\n",
      "gradient ==>  2.6563570282754654 -2.6136612524416023\n",
      "0.642596731964138 0.35165727175336836 ==> logProbability =  -531.4136054041694\n",
      "gradient ==>  2.6149345130589836 -2.5695502127567806\n",
      "0.6497294256928436 0.34464837168470686 ==> logProbability =  -527.7789409701099\n",
      "gradient ==>  2.573536995267773 -2.5255805545741623\n",
      "0.6568666802012982 0.33764411597253124 ==> logProbability =  -524.2045432339611\n",
      "gradient ==>  2.5321203468643034 -2.481704468402995\n",
      "0.664008489190317 0.3306445042429872 ==> logProbability =  -520.6903941732023\n",
      "gradient ==>  2.4906382381420826 -2.437872674371647\n",
      "0.6711548516275676 0.3236495414900161 ==> logProbability =  -517.2365445980367\n",
      "gradient ==>  2.449041812689302 -2.3940341273896593\n",
      "0.6783057714348253 0.31665923778344013 ==> logProbability =  -513.8431174112873\n",
      "gradient ==>  2.407279322213242 -2.3501356939175366\n",
      "0.6854612571221476 0.3096736079207488 ==> logProbability =  -510.5103113792047\n",
      "gradient ==>  2.365295714480453 -2.3061217952547395\n",
      "0.692621321350828 0.3026926710036028 ==> logProbability =  -507.2384054742576\n",
      "gradient ==>  2.323032166349037 -2.2619340113863586\n",
      "0.6997859804022407 0.295716449915004 ==> logProbability =  -504.02776386164544\n",
      "gradient ==>  2.2804255523225265 -2.21751063835751\n",
      "0.7069552535235368 0.2887449706665044 ==> logProbability =  -500.87884161396016\n",
      "gradient ==>  2.2374078371605037 -2.1727861908480577\n",
      "0.7141291621131002 0.2817782615762245 ==> logProbability =  -497.7921912535902\n",
      "gradient ==>  2.193905378760462 -2.1276908400146795\n",
      "0.7213077286981083 0.2748163522271591 ==> logProbability =  -494.76847024067405\n",
      "gradient ==>  2.1498381246678377 -2.082149774695665\n",
      "0.7284909756425907 0.26785927214032784 ==> logProbability =  -491.8084495463909\n",
      "gradient ==>  2.1051186820340604 -2.0360824716158845\n",
      "0.7356789235058305 0.26090704907749784 ==> logProbability =  -488.9130234780406\n",
      "gradient ==>  2.059651236455295 -1.9894018571725383\n",
      "0.7428715889461227 0.2539597068616554 ==> logProbability =  -486.0832209548747\n",
      "gradient ==>  2.013330289636656 -1.9420133395257153\n",
      "0.7500689820313775 0.24701726256758105 ==> logProbability =  -483.32021847350643\n",
      "gradient ==>  1.9660391789653318 -1.8938136848468048\n",
      "0.7572711027724243 0.2400797228861534 ==> logProbability =  -480.6253550508827\n",
      "gradient ==>  1.9176483334213117 -1.844689705351584\n",
      "0.7644779366321237 0.23314707939909235 ==> logProbability =  -478.00014949378965\n",
      "gradient ==>  1.8680132093161887 -1.7945167187342577\n",
      "0.7716894486762231 0.22621930240803606 ==> logProbability =  -475.446320420016\n",
      "gradient ==>  1.8169718354677684 -1.743156728203303\n",
      "0.778905575909368 0.21929633283168634 ==> logProbability =  -472.96580955202774\n",
      "gradient ==>  1.7643418797093773 -1.6904562586395855\n",
      "0.7861262171652261 0.21237807149994992 ==> logProbability =  -470.5608089252417\n",
      "gradient ==>  1.7099171260142043 -1.6362437662081675\n",
      "0.7933512196677762 0.2054643649081032 ==> logProbability =  -468.2337928076907\n",
      "gradient ==>  1.653463222521907 -1.5803265142687337\n",
      "0.8005803610112123 0.19855498610558975 ==> logProbability =  -465.9875553269826\n",
      "gradient ==>  1.5947125236144757 -1.5224867749643067\n",
      "0.8078133247539833 0.1916496088171455 ==> logProbability =  -463.825255059048\n",
      "gradient ==>  1.5333578017032892 -1.4624771693844423\n",
      "0.815049666981657 0.1847477720207568 ==> logProbability =  -461.75046817240514\n",
      "gradient ==>  1.4690445441060547 -1.400014893417108\n",
      "0.8222887698830555 0.17784883085685613 ==> logProbability =  -459.76725217168786\n",
      "gradient ==>  1.4013614749993053 -1.334774481320494\n",
      "0.8295297762888806 0.170951887604168 ==> logProbability =  -457.8802228887293\n",
      "gradient ==>  1.3298288509621443 -1.2663786182286572\n",
      "0.8367714956701059 0.16405569297208386 ==> logProbability =  -456.094648193587\n",
      "gradient ==>  1.2538839745046744 -1.194386298309496\n",
      "0.8440122662049209 0.1571585020901265 ==> logProbability =  -454.41656304098615\n",
      "gradient ==>  1.1728632684962577 -1.1182772876991294\n",
      "0.8512497470571784 0.15025785930026944 ==> logProbability =  -452.8529120879383\n",
      "gradient ==>  1.085980201264249 -1.0374312990292083\n",
      "0.8584805954710314 0.14335026701236775 ==> logProbability =  -451.41172848080475\n",
      "gradient ==>  0.9922984700242523 -0.951099338098004\n",
      "0.8656999445611133 0.13643065728959197 ==> logProbability =  -450.10236099238324\n",
      "gradient ==>  0.8907004619593977 -0.8583629683359391\n",
      "0.8729005149889555 0.12949150852957217 ==> logProbability =  -448.9357674432349\n",
      "gradient ==>  0.7798529864802504 -0.7580739062373709\n",
      "0.8800709995200816 0.12252127527745774 ==> logProbability =  -447.9249024408965\n",
      "gradient ==>  0.658178091364789 -0.64875928050526\n",
      "0.887192842022463 0.11550134939670412 ==> logProbability =  -447.08524786926955\n",
      "gradient ==>  0.5238542884595745 -0.5284609470052146\n",
      "0.8942328877799539 0.10839939503664005 ==> logProbability =  -446.4355858526011\n",
      "gradient ==>  0.3749318730450568 -0.394429357271747\n",
      "0.9011225454928886 0.1011514562538826 ==> logProbability =  -445.99929386333514\n",
      "gradient ==>  0.20988621450715073 -0.24241777428181877\n",
      "0.9076681245250965 0.09359133752907936 ==> logProbability =  -445.8075221506318\n",
      "gradient ==>  0.03046838065938573 -0.06432068837585803\n",
      "0.9119490667138523 0.0845539964391055 ==> logProbability =  -445.9328320226725\n",
      "\n",
      "Best parameter values found:\n",
      "\n",
      "Parameter values of the keyboard model:\n",
      "pr_hit = 0.9076681245250965\n",
      "pr_miss = 0.09233187547490351\n",
      "deg_kb = 2\n",
      "\n",
      "Parameter values of the spelling model:\n",
      "pr_repeat = 0.09359133752907936\n",
      "pr_moveOn = 0.9064086624709207\n",
      "deg_sp = 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9076681245250965,\n",
       " 0.09233187547490351,\n",
       " 0.09359133752907936,\n",
       " 0.9064086624709207)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learnBestParameterValuesGivenDocument1WhenTypingDocument2_GradientAscent('H.txt','biolaVision.txt', trace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-611.8687674381492"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_hit=0.7175985660046966\n",
    "pr_miss=0.2824014339953034\n",
    "pr_repeat=0.08074405950443056\n",
    "pr_moveOn=0.9192559404955695\n",
    "logPrOfGettingDocument1WhenTypingDocument2('B.txt','biolaVision.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-612.5797385070729"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_hit=0.7\n",
    "pr_miss=0.3\n",
    "pr_repeat=0.1\n",
    "pr_moveOn=0.9\n",
    "logPrOfGettingDocument1WhenTypingDocument2('B.txt','biolaVision.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pr_hit: 0.44921427313199863   pr_repeat: 0.37160544815706487\n",
      "Current logProbability =  -933.6201702288232\n",
      "************************************\n",
      "gradient ==>  1.6350627914121105 -0.8472334976219145\n",
      "0.45809309814899746 0.3670047453501542 ==> logProbability =  -931.8104365083852\n",
      "gradient ==>  1.5273211282672037 -0.79547450452867\n",
      "0.4669622514804079 0.3623854251421657 ==> logProbability =  -930.120768059395\n",
      "gradient ==>  1.4207098094782395 -0.7429523327900824\n",
      "0.4758237156300414 0.3577513715036371 ==> logProbability =  -928.5504938097674\n",
      "gradient ==>  1.3150147719472898 -0.6896757473330126\n",
      "0.4846796534584357 0.35310676547302333 ==> logProbability =  -927.0991304296595\n",
      "gradient ==>  1.2100253268290544 -0.6356560560324169\n",
      "0.493532449570173 0.3484561740048325 ==> logProbability =  -925.7663753977174\n",
      "gradient ==>  1.1055321945273135 -0.5809085016969675\n",
      "0.5023847667709158 0.34380467100285206 ==> logProbability =  -924.5521008577098\n",
      "gradient ==>  1.0013253770976007 -0.5254541467285208\n",
      "0.5112396252234257 0.3391580074916846 ==> logProbability =  -923.4563479693386\n",
      "gradient ==>  0.8971917435881096 -0.4693225023345349\n",
      "0.5201005172786921 0.3345228600307167 ==> logProbability =  -922.479321323354\n",
      "gradient ==>  0.792912133599657 -0.4125553288612309\n",
      "0.5289715813004195 0.3299072102257149 ==> logProbability =  -921.6213827191395\n",
      "gradient ==>  0.6882576491627788 -0.3552123721259477\n",
      "0.5378578793368853 0.32532095824756274 ==> logProbability =  -920.8830430255232\n",
      "gradient ==>  0.5829845264477171 -0.2973805074525444\n",
      "0.5467658727187538 0.32077698928765674 ==> logProbability =  -920.2649495196575\n",
      "gradient ==>  0.4768263493468794 -0.2391893883935836\n",
      "0.5557043167858986 0.316293216583948 ==> logProbability =  -919.7678626806113\n",
      "gradient ==>  0.3694807600272725 -0.1808409339806758\n",
      "0.5646861845339942 0.31189707603163175 ==> logProbability =  -919.3926059965091\n",
      "gradient ==>  0.26058296260180214 -0.12267312581764145\n",
      "0.5737337581479522 0.3076378024198512 ==> logProbability =  -919.1399313224008\n",
      "gradient ==>  0.14963938985442837 -0.06533147569325592\n",
      "0.5828983820042772 0.30363659390590453 ==> logProbability =  -919.0099877828079\n",
      "gradient ==>  0.035780302819944154 -0.01045936933246594\n",
      "0.5924966895027965 0.30083079755480063 ==> logProbability =  -918.9951261084735\n",
      "gradient ==>  -0.08509968349574137 0.029199764585882804\n",
      "0.5830380054045293 0.3040763013876728 ==> logProbability =  -919.0062662141879\n",
      "\n",
      "Best parameter values found:\n",
      "\n",
      "Parameter values of the keyboard model:\n",
      "pr_hit = 0.5924966895027965\n",
      "pr_miss = 0.40750331049720345\n",
      "deg_kb = 2\n",
      "\n",
      "Parameter values of the spelling model:\n",
      "pr_repeat = 0.30083079755480063\n",
      "pr_moveOn = 0.6991692024451994\n",
      "deg_sp = 2\n",
      "Learned Parameters:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5924966895027965,\n",
       " 0.40750331049720345,\n",
       " 0.30083079755480063,\n",
       " 0.6991692024451994)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming the function is already implemented and available in your environment\n",
    "# Example usage:\n",
    "corrupted_file = \"corruptedBiolaVision.txt\"  # Training dataset\n",
    "original_file = \"biolaVision.txt\"           # Original document used to learn parameters\n",
    "\n",
    "# Call the function to learn the best parameter values\n",
    "learned_params = learnBestParameterValuesGivenDocument1WhenTypingDocument2_GradientAscent(\n",
    "    corrupted_file,\n",
    "    original_file,\n",
    "    trace=True  # Enable tracing for detailed logging\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Display learned parameters\n",
    "print(\"Learned Parameters:\")\n",
    "learned_params\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recovered message saved to recoveredMessage_V1.txt\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_pr_s_given_w(s, w, params):\n",
    "    \"\"\"\n",
    "    Compute the probability P(s | w, X) given the learned parameters.\n",
    "    Args:\n",
    "        s (str): The corrupted string.\n",
    "        w (str): A candidate word from the vocabulary.\n",
    "        params (dict): Learned parameters including Prhit, Prmiss, etc.\n",
    "    Returns:\n",
    "        float: The computed probability.\n",
    "    \"\"\"\n",
    "    pr_hit = params['Prhit']\n",
    "    pr_miss = params['Prmiss']\n",
    "    deg_kb = params['deg_kb']\n",
    "\n",
    "    # Calculate character-level probabilities\n",
    "    match_prob = pr_hit if s == w else pr_miss\n",
    "    return match_prob ** len(s)\n",
    "\n",
    "def recover_message_v1(corrupted_file, vocab_file, output_file, params):\n",
    "    \"\"\"\n",
    "    Recover the unknown message using Option R.\n",
    "    Args:\n",
    "        corrupted_file (str): Path to corruptedMessage1.txt.\n",
    "        vocab_file (str): Path to vocabulary.txt.\n",
    "        output_file (str): Path to save recoveredMessage_V1.txt.\n",
    "        params (dict): Learned parameters including Prhit, Prmiss, etc.\n",
    "    \"\"\"\n",
    "    # Load corrupted message and vocabulary\n",
    "    with open(corrupted_file, 'r') as cf:\n",
    "        corrupted_lines = cf.read().splitlines()\n",
    "\n",
    "    with open(vocab_file, 'r') as vf:\n",
    "        vocabulary = vf.read().splitlines()\n",
    "\n",
    "    recovered_lines = []\n",
    "\n",
    "    for s in corrupted_lines:\n",
    "        # Compute probabilities for each word in the vocabulary\n",
    "        word_probs = [(w, compute_pr_s_given_w(s, w, params)) for w in vocabulary]\n",
    "        \n",
    "        # Sort by probability and get the top 4 candidates\n",
    "        top_candidates = sorted(word_probs, key=lambda x: x[1], reverse=True)[:4]\n",
    "        \n",
    "        # Save only the words (not their probabilities)\n",
    "        recovered_lines.append(' '.join([w for w, _ in top_candidates]))\n",
    "\n",
    "    # Save the recovered message to file\n",
    "    with open(output_file, 'w') as of:\n",
    "        of.write('\\n'.join(recovered_lines))\n",
    "\n",
    "    print(f\"Recovered message saved to {output_file}\")\n",
    "\n",
    "\n",
    "# Example Usage:\n",
    "corrupted_file = \"corruptedMessage1.txt\"\n",
    "vocab_file = \"vocabulary.txt\"\n",
    "output_file = \"recoveredMessage_V1.txt\"\n",
    "\n",
    "# Example learned parameters from Step 1\n",
    "learned_params = {\n",
    "    'Prhit': 0.5924966895027965,\n",
    "    'Prmiss': 0.40750331049720345,\n",
    "    'deg_kb': 2\n",
    "#     pr_hit = 0.5947958590184448\n",
    "# pr_miss = 0.4052041409815552\n",
    "}\n",
    "\n",
    "# Recover the message\n",
    "recover_message_v1(corrupted_file, vocab_file, output_file, learned_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recovered message saved to recoveredMessage_V2.txt\n"
     ]
    }
   ],
   "source": [
    "def compute_pr_s1_s2_given_w(s1, s2, w, params):\n",
    "    \"\"\"\n",
    "    Compute the joint probability P(s1 | w, X) * P(s2 | w, X).\n",
    "    Args:\n",
    "        s1 (str): The first corrupted string.\n",
    "        s2 (str): The second corrupted string.\n",
    "        w (str): A candidate word from the vocabulary.\n",
    "        params (dict): Learned parameters including Prhit, Prmiss, etc.\n",
    "    Returns:\n",
    "        float: The joint probability.\n",
    "    \"\"\"\n",
    "    pr_s1_given_w = compute_pr_s_given_w(s1, w, params)\n",
    "    pr_s2_given_w = compute_pr_s_given_w(s2, w, params)\n",
    "    return pr_s1_given_w * pr_s2_given_w\n",
    "\n",
    "\n",
    "def recover_message_v2(corrupted_file1, corrupted_file2, vocab_file, output_file, params):\n",
    "    \"\"\"\n",
    "    Recover the unknown message using Option T.\n",
    "    Args:\n",
    "        corrupted_file1 (str): Path to corruptedMessage1.txt.\n",
    "        corrupted_file2 (str): Path to corruptedMessage2.txt.\n",
    "        vocab_file (str): Path to vocabulary.txt.\n",
    "        output_file (str): Path to save recoveredMessage_V2.txt.\n",
    "        params (dict): Learned parameters including Prhit, Prmiss, etc.\n",
    "    \"\"\"\n",
    "    # Load corrupted messages and vocabulary\n",
    "    with open(corrupted_file1, 'r') as cf1:\n",
    "        corrupted_lines1 = cf1.read().splitlines()\n",
    "\n",
    "    with open(corrupted_file2, 'r') as cf2:\n",
    "        corrupted_lines2 = cf2.read().splitlines()\n",
    "\n",
    "    with open(vocab_file, 'r') as vf:\n",
    "        vocabulary = vf.read().splitlines()\n",
    "\n",
    "    # Ensure both corrupted files have the same number of lines\n",
    "    if len(corrupted_lines1) != len(corrupted_lines2):\n",
    "        raise ValueError(\"The two corrupted files do not have the same number of lines.\")\n",
    "\n",
    "    recovered_lines = []\n",
    "\n",
    "    # Process each pair of corrupted strings\n",
    "    for s1, s2 in zip(corrupted_lines1, corrupted_lines2):\n",
    "        # Compute joint probabilities for each word in the vocabulary\n",
    "        word_probs = [\n",
    "            (w, compute_pr_s1_s2_given_w(s1, s2, w, params)) for w in vocabulary\n",
    "        ]\n",
    "        \n",
    "        # Sort by joint probability and get the top 4 candidates\n",
    "        top_candidates = sorted(word_probs, key=lambda x: x[1], reverse=True)[:4]\n",
    "        \n",
    "        # Save only the words (not their probabilities)\n",
    "        recovered_lines.append(' '.join([w for w, _ in top_candidates]))\n",
    "\n",
    "    # Save the recovered message to file\n",
    "    with open(output_file, 'w') as of:\n",
    "        of.write('\\n'.join(recovered_lines))\n",
    "\n",
    "    print(f\"Recovered message saved to {output_file}\")\n",
    "\n",
    "\n",
    "# Example Usage:\n",
    "corrupted_file1 = \"corruptedMessage1.txt\"\n",
    "corrupted_file2 = \"corruptedMessage2.txt\"\n",
    "vocab_file = \"vocabulary.txt\"\n",
    "output_file = \"recoveredMessage_V2.txt\"\n",
    "\n",
    "# Example learned parameters from Step 1\n",
    "learned_params = {\n",
    "    'Prhit': 0.9076681245250965,\n",
    "    'Prmiss': 0.09233187547490351,\n",
    "    'deg_kb': 2\n",
    "}\n",
    "\n",
    "# Recover the message\n",
    "recover_message_v2(corrupted_file1, corrupted_file2, vocab_file, output_file, learned_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics saved to accuracy_statistics.txt\n"
     ]
    }
   ],
   "source": [
    "def gather_statistics(real_message_file, recovered_file, output_file):\n",
    "    \"\"\"\n",
    "    Gather accuracy statistics for spelling recognition.\n",
    "    Args:\n",
    "        real_message_file (str): Path to the actual message (messageX.txt).\n",
    "        recovered_file (str): Path to the recovered message file.\n",
    "        output_file (str): Path to save the statistics report.\n",
    "    \"\"\"\n",
    "    # Load the real message and recovered message\n",
    "    with open(real_message_file, 'r') as rmf:\n",
    "        real_lines = rmf.read().splitlines()\n",
    "\n",
    "    with open(recovered_file, 'r') as rf:\n",
    "        recovered_lines = rf.read().splitlines()\n",
    "\n",
    "    # Ensure both files have the same number of lines\n",
    "    if len(real_lines) != len(recovered_lines):\n",
    "        raise ValueError(\"The real message and the recovered message do not have the same number of lines.\")\n",
    "\n",
    "    total_words = 0\n",
    "    correct_top1 = 0\n",
    "    correct_top4 = 0\n",
    "\n",
    "    for real_word, recovered_line in zip(real_lines, recovered_lines):\n",
    "        recovered_words = recovered_line.split()  # Top 4 recovered words\n",
    "        total_words += 1\n",
    "\n",
    "        if real_word == recovered_words[0]:  # Check top-1 accuracy\n",
    "            correct_top1 += 1\n",
    "\n",
    "        if real_word in recovered_words:  # Check if the real word is in the top 4\n",
    "            correct_top4 += 1\n",
    "\n",
    "    # Calculate accuracy\n",
    "    top1_accuracy = correct_top1 / total_words * 100\n",
    "    top4_accuracy = correct_top4 / total_words * 100\n",
    "\n",
    "    # Write statistics to the output file\n",
    "    with open(output_file, 'w') as of:\n",
    "        of.write(f\"Total Words: {total_words}\\n\")\n",
    "        of.write(f\"Correct Top-1 Predictions: {correct_top1}\\n\")\n",
    "        of.write(f\"Top-1 Accuracy: {top1_accuracy:.2f}%\\n\")\n",
    "        of.write(f\"Correct Top-4 Predictions: {correct_top4}\\n\")\n",
    "        of.write(f\"Top-4 Accuracy: {top4_accuracy:.2f}%\\n\")\n",
    "\n",
    "    print(f\"Statistics saved to {output_file}\")\n",
    "\n",
    "\n",
    "# Example Usage:\n",
    "real_message_file = \"messageX.txt\"\n",
    "recovered_file = \"recoveredMessage_V2.txt\"  # Assuming Step 3 output\n",
    "output_file = \"accuracy_statistics.txt\"\n",
    "\n",
    "# Gather accuracy statistics\n",
    "gather_statistics(real_message_file, recovered_file, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
